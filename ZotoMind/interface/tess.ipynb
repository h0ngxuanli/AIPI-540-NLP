{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/lihongxuan/Desktop/AIPI/Courses/AIPI540/AIPI-540-NLP/ZotoMind/interface/tess.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m))))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrag_pipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_retriever\n\u001b[0;32m----> 8\u001b[0m retriever \u001b[38;5;241m=\u001b[39m build_retriever(\n\u001b[1;32m      9\u001b[0m                 zotero_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10papers\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     10\u001b[0m                 paper_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                 user_exist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     12\u001b[0m                 update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     13\u001b[0m                 )\n",
      "File \u001b[0;32m~/Desktop/AIPI/Courses/AIPI540/AIPI-540-NLP/ZotoMind/rag/rag_pipeline.py:49\u001b[0m, in \u001b[0;36mbuild_retriever\u001b[0;34m(zotero_key, paper_path, user_exist, update)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# create retriever with vetorestore and docstore\u001b[39;00m\n\u001b[1;32m     48\u001b[0m id_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 49\u001b[0m cs \u001b[38;5;241m=\u001b[39m ChromaStore(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./attachments/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzotero_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocstore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m PineconeVectorStore(index_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzotomind-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzotero_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, embedding\u001b[38;5;241m=\u001b[39mOpenAIEmbeddings())\n\u001b[1;32m     51\u001b[0m store \u001b[38;5;241m=\u001b[39m create_kv_docstore(cs)\n",
      "File \u001b[0;32m~/Desktop/AIPI/Courses/AIPI540/AIPI-540-NLP/ZotoMind/rag/utils/rag_utils.py:18\u001b[0m, in \u001b[0;36mChromaStore.__init__\u001b[0;34m(self, path, table_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, table_name):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{path}\u001b[39;00m\u001b[38;5;124m/chroma.sqlite3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mpath))\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable \u001b[38;5;241m=\u001b[39m Table(table_name)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_column \u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"/Users/lihongxuan/Desktop/AIPI/Courses/AIPI540/AIPI-540-NLP/ZotoMind/interface/tess.ipynb\"))))\n",
    "\n",
    "from rag.rag_pipeline import build_retriever\n",
    "retriever = build_retriever(\n",
    "                zotero_key = \"10papers\", \n",
    "                paper_path = None,\n",
    "                user_exist = True, \n",
    "                update = False\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# List of Papers\n",
      "## Understanding AI\n",
      "- **Date**: 2024-04-01\n",
      "- **Authors**: Alice Smith, Bob Johnson\n",
      "- **Field**: Artificial Intelligence\n",
      "\n",
      "## Exploring Space\n",
      "- **Date**: 2024-03-15\n",
      "- **Authors**: Chris Doe\n",
      "- **Field**: Astronomy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "papers = [\n",
    "    {\"title\": \"Understanding AI\", \"date\": \"2024-04-01\", \"authors\": [\"Alice Smith\", \"Bob Johnson\"], \"field\": \"Artificial Intelligence\"},\n",
    "    {\"title\": \"Exploring Space\", \"date\": \"2024-03-15\", \"authors\": [\"Chris Doe\"], \"field\": \"Astronomy\"}\n",
    "]\n",
    "\n",
    "markdown_string = \"# List of Papers\\n\"\n",
    "for paper in papers:\n",
    "    markdown_string += f\"## {paper['title']}\\n\"\n",
    "    markdown_string += f\"- **Date**: {paper['date']}\\n\"\n",
    "    markdown_string += f\"- **Authors**: {', '.join(paper['authors'])}\\n\"\n",
    "    markdown_string += f\"- **Field**: {paper['field']}\\n\\n\"\n",
    "\n",
    "print(markdown_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"/Users/lihongxuan/Desktop/AIPI/Courses/AIPI540/AIPI-540-NLP/ZotoMind/interface/tess.ipynb\"))))\n",
    "\n",
    "from rag.rag_pipeline import retrieve, build_retriever\n",
    "\n",
    "retriever = build_retriever(\n",
    "                zotero_key = \"10papers\", \n",
    "                paper_path = None,\n",
    "                user_exist = True, \n",
    "                update = False\n",
    "                )\n",
    "query = \"Can you give me some experiments tables regarding LLMs application on protein discovery?\"\n",
    "response, images = retrieve(retriever, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "These images are for your reference: \n",
       "\n",
       "Paper Title:  The language of proteins: NLP, machine learning & protein sequences, <img width=\"80%\" height=\"80%\" src=\"data:image/jpeg;base64,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\" />\n",
       "\n",
       "Paper Title:  Chapter 6 Cell Systems Learning the protein language: Evolution, structure, and function, <img width=\"80%\" height=\"80%\" src=\"data:image/jpeg;base64,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\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "response = \"\"\n",
    "response += (\"These images are for your reference: \\n\\n\" +  \n",
    "    \"\\n\\n\".join(['Paper Title: {}, <img width=\"80%\" height=\"80%\" src=\"data:image/jpeg;base64,{}\" />'.format(image.metadata['title'], image.page_content) for image in images]))\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These images are for your reference: \n",
      "Paper Title:  The language of proteins: NLP, machine learning & protein sequences, <img width=\"80%\" height=\"80\" src=\"data:image/jpeg;base64,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\" />\n",
      "Paper Title:  Chapter 6 Cell Systems Learning the protein language: Evolution, structure, and function, <img width=\"80%\" height=\"80\" src=\"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQgJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABMAOgDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iimu6xoXdgqjqWOAKAHVna5q8Wh6RPfyoX8sAKgONzE4AzUU3ijQrfO/VrTjqEkDH9M1yXibUT40jh0rw+jXSxv508xBRF4IA+bHqfy711UMPKU1zq0er2ODFYuMKb9nJOfRLV39B1h8UbeSYJf2DwoT/rIn34+owP0/Ku7tbu3vrZLm1mSWFxlXQ5BrwPUtKvtIuRb39u0MpXcASDkeoI4NdT8OdaltNZ/sx3zbXWSFPRZAM5H1Ax+VelisDT9n7Sj0PGwOa1vbKjiOum1mn5nrNFFcl428VtoNslrZkfbp1yGIz5S9N2O59Poa8elSlVmoR3Z9FXrwoU3Unsjq3ljiGZHVB6scUJJHKMxurj1U5rw+w0bXPFU8k8YkuMHDzzv8oPpk/yFLfaJr3hWVLp1ktxuws8EmRn0yOn0PWvS/s+F+T2i5ux4v9sVOX2nsXyd/wClY9xork/BHiltetHtrsr9ugALEDHmJ/ex656/h611lebVpSpTcJbo9qhXhXpqpDZhRRXO+OiR4M1Ag44j/wDRi0qcOeaj3HWqezpyn2TZ0VFeR+CmY6P4myT/AMeLd/8AZeovh8Hl8QTxgklrSQAE9+K75YDlU3zfD5HlQzXndNcnx367Wdux7DRXjLfD/wASRjclojMDwFnUH9TVe01zX/C2pGGSSZWQ/vLacllI+n9RVf2fGa/dVE2Q83nTa9vScV3/AKR7dRVXTr6LU9Ot72DPlzIHAPUex+nSrVeY007M9yMlJJrZhRRRSGFFFFABRRRQAUUUUAFFFFAFTVNRg0nTZ765JEUS5IHVj2A9yeK8S1zxFqGv3TSXUrCIH93Ap+RB9O59+td78Ubh00eytwSFknLNg9do6fr+lebaZaC/1W0sy+wTzLGWzjAJxXv5dRhGn7aW/wCiPks5xFSdZYeL00+bZVr174eWa6f4XFzNiNrqQyZfj5R8o/Dgn8a2bLwxommwqkOnW528+ZKgdv8Avo814trGoPqerXN27swkkYpuP3UzwB6ACqdRY5OnHRLqQqLyqUas7Sk7pLt31Or+I2t6fqc1pbWUsc7QbjJKnIGcYAPQ9O3tWB4SiebxZpix/eE4Y8dhyf0BrGVWd1RFLMxwABkk16r4D8Jy6UranfpsupV2xxHrGvcn3Pp2H1wNqrhhcPyX9PmYUFVx+MVS3VN9kl/wx3FeIeNblrrxdfs2cI4jUHsFAH+J/Gvb68O8ZW7W3i7UUb+KTzBx2YA/1rzsqt7V+n6nsZ9f2EbbX/Q9i0XT4tK0a1s4gAI4xkju3Un8Tmn6pptvq+nTWN0GMUowSpwQc5BHvmjSb2PUdItLuI5WWJW+hxyPqDkU/UL+DTLCa9uWKwxLuYgc/Qe9ec3P2n96/wCNz2EqfsbfZt8rW/yMTRPBmneH783trc3ZfYUYSupUg+uFHoK8/wBc8S6r4m1g2dhJKtuz+XBBE23eM9W9c9eeB+tdrL4x07W9L1S208XPnrYzSZZMYAU89fUivNPD41U6vG2jAG+VWKcIcDGDjdx0Nezhac251a3xLa585j6tNKnRw3wNu/L11tYv3vhnxD4bt11AhokGN0lvLzGegzj/AOuK2z4nm13wBq1tesGu7cRHeBjzFMi849R3+opbqH4h3trLa3EbSQyqVdcQDIP0rFPhzWdH0rU7i9sjDC1uqFjIp582Mjofatk41EvaOLkmrWfmcrjOi2qMZqDTvzLyZc8Ff8gfxN/14N/6C9N+GxA8UsScAWz5J+op3gr/AJA/ib/rwb/0F6i+HkZl8RTRg4L2kign3xTq/DW+X5Cw/wAWG+f/AKUz1R9Z0uNdz6lZqvq06j+teT+PdVs9W8QrJZSCWOKERGRejEFjx6jnrWn/AMKt1H/n/tfyb/CtPSPhlBBOs2qXQuFXpDECqn6nrj24rjofVcPL2indno4r69jI+ydLlV97nOandanpHhrw/FBeXNsZIZZCsUrJkM+4Zxjsf1p48SeIdYsrTTNLa9eSGP8AfSRktJISepbqAOB1rS+KYAvNNAGAInwB9RXRfDq1ig8KRTIo8y4kdnPc4JUfoK2lVhHDxrOKbbf4tnPChUnjJYaM2opK/oktu1zn18Q6h4S8LJZ3CN/a00zsqznd5acfN1556fj6YrMtdJ8YeILT+0Fubh42JaMSXBTd/ujOB+gqP4ivI3i6UOMKkSBPdcZ/mTWlYn4gpYW62akWwiXygFgxsxx19qtLlpqpHlUpau/5IylLnrSoz53GGiUfzZBoPizVfD+rf2brLSyQbwkgnbLQ+4Pp7enStn4geKb3TbmLTNPl8ktGJJJUPzYJICj06Zz9K5zUfDHi/Vrs3V7YmWcgKX3RLkDp0IrpNb8EXes6XptwkixajBaRwzRynIcqP7wzznP1rOawyqwqSa87bX7m1N4x0KlKClpa19Ha+q/pmJZ+FPFGpadFqUepcypvRXuX3kH3xjnjv9as+C/F2oprEWlalM80UzeWrTH5435wMnk5PGD/APrzFg8ZeFom8tbuK3XJOzEsaj1xyB+lb3hv4iXF1fwWOqQxnznEaTxDGGPA3D69xirrRnOnLSM10to0Z4eVOnVguaVOXW92n/l9xl+K/FeqX2uzabYXEkEEUpgVYm2l2BwSW+v4Umo+F/FGi2MmonUi4jAaTyLiTeB68gZxWj4n+H15cajcX+lukomcyNA7bWDHk4J4Iz64rHbV/GXhoKly90kSnA89BIh9txz+hp05RlCKoOPmnu/6+Yq0ZxqTli1Lyaei/rTsdX4B8U3OsrNYX7iS4hXekvQuucHP0yOfeip/CHjQ+IJnsruBYrtE3ho/uuAeeD0PI9aK8fFxcarvHl8j6LL5qWHi1Pm89n8yz460eTV/Dr+RGXuLdhKijqwHDAfgc/hXjAJVgykgg5BHavo2uN1/4e2WqztdWUos52JLgLlHPrjsfp+VdmAxsaS9nU2PNzXLZ15e2pb9Ucvp3ijX/Ek0Ggvcxqt0dkk6xgPswS3t0B7V2UHw+8OxIA9pJMR/FJM2T+RAqh4R8D3Gham99ezwyOqlIliJIGepOQO3867es8ViFGfLh3ZeWmptgMJKVPmxavLpfWyM+x0PS9MbdZ2EEL4xvVBu/PrWhRRXnyk5O7dz2IwjBWirIK4rx54Vm1eJNRsE33cK7XjHWROvHuOfr+VdrRV0asqU1OJliMPDEU3TnszxDR/FOseG/MtoSuwN80FwhIVu/HBFLq3ibWvFLRWjqCpbK29tGfmb1xyTXsl1pthfEG7sra4I6GWJWx+YpbXTrKxz9ks7e33dfKiVM/kK9L6/Rvz+z948X+ycRy+y9t7nb+v+GOb8FeFjoumyyXqD7XdDEiZyET+79fX/AOtXA6hpmqeC9eS6iVtkUhMFwVyjg54PvjII/wD117XSMqupV1DKeoIyK56eOnGcpSV1LdHZWyunOlCFN8rjszybUfiPql9Zi3toY7SRsbpY2JY/7vp+tWpLfXD4D1W+1m5uGEqxiGGZjkDzFyxHbPGPx9a9Hi06xgl82Kzt45M53pEoP54qzVPGU42VOFtb+ZnHLq0m3WquTaaXb7up5F4K/wCQP4m/68G/9Bek+Gv/ACNR/wCvd/5ivXqKc8fzKa5fi8/KwqeVcjpPn+C/Te7v3CiiivNPaPMvip/x+6b/ANc3/mK6fwB/yJll/vSf+htXSlVbqoP1FAAAwAAPauueJ5qEaNtuv3nn08FyYqWI5t1t93+Rw3xA8L3GqCLUrCJpbiJdksa9WTkggdyMnjvn2rntH+IV9pGnJYT2aXHkrsjZnKMoHQHg5x07V63VafTrG5kElxZW8rjkNJErH8yK0p4uPs1Sqx5ktjGtl8/bOth58snv1TPLbG/8T+MNcDQXdza25IEht5GSKJR16Hlv1P06aXj3TNWtLpdRsZ7s2ZjVZAkrEowGMnnoQBz65z159HjjSJAkaKiDoqjAFOp/XbVFKMUkuglll6UoTm3J63/4FzzKx+J8kGnJDdacZ7hEC+YJsCQ+pGOP89Kw/CujXmueIobpYAltHOJpXC7UADZ2j+QAr159K06WTzJLC1d/7zQqT+eKtKqooVVCqOgAwBV/XacIy9lCzfmZ/wBm1akovEVOZR20/N/I8i19dd8M+ImuBPctbCbzYWMjGNlzkKe3sRVvWPiKuqaJPYjSwkk6FGZ5Nyr7gY5P8jXqTKrqVZQynqCMg1VTStOjk8yOwtVf+8sKg/niksZTkoupC7XVaDll1aLkqNW0Zbpq/wBx578N9Cu11BtWnhMdusZSIuMF2OOQPTGeff60V6bRXLiK7rz52d+DwscLSVOLuFFFFc51hRRRQAUUUUAFVdQ1G20y1NxdPtQHAAGSx9APWrVc9qIFx4x0uCXmKOJ5VU9C/P8ALANAEjeIbiKPz59GvY7bqZOCQPUr1FaEmqW66S+pRt5sCoXBTqR/jV3rXGRAQ6P4ltI/9RDK/ljsueo/SgDWTxHLJEsy6LqDRsoYMqA5B7jmrB8QWZ0WXVIg7xRnDpjDKcgYI9eaoadrzRaVaRLpGpyFIEUMsHythRyDnpVC6s7m38J6xcXUfkyXc3neVnOwF14PvQBsLr9wyhl0TUCCMg7R/jUl5ryafpUV/c2k8YeTZ5RA3L168+1V7fU9YW2iC6A7KEAB+1IM8VH4iZ59M0xp4PKd72LfEWDY68Z70Ab8E0dzAk0TBo5FDKw7g1X07UY9SjneNGUQzNCd3cjv+tZenk6HqzaVIT9juCZLNj/Cf4k/w/8Ar0/wt/x7ah/1/wAv9KAN2suXXraLW00sq/mNgGT+FWIJCn3OK0J5kt7eSeQ4SNSzH2AzXD+faXHh25u3vbdNSln+1qpkG5Sp+VcfTOPrQB3UkiRRtJIwVFBLMTgAViL4ikuQZLHSru5twceaMKG/3QeTVXX7/wC3eEYriI7UuWjDkfwgnkfmMV0kUaQxJFGoVEUKoHYCgCrpuqW+qQtJBuVkbbJHIMMh9CKpyeIA9zJBp9lPfNEcSPHgIp9Mnqak1CK3s7bVLu1CrePbszlWOThTg4zR4bhjh8PWQjAw0Ydvcnk0AP07WYb+eS2eKW2u4xloZhg49R6iqg8SGSeeO30u8nEMrRM0YBGQfrWnLa2jahDcyKoulUrG27BI7jGea5rR7y/trjVVtNLa7Q30hLiZUwc9MGgDfsdSlvJWSTT7q1VV3b5gAD7VTHiF7gs1hplzdwKSDMuFVsf3c9auWc95fJNHe6c1opXAJmV92c56dKybNNa0C2FotlHf2sZOx4pNjgE55B69e1AGxp+rW2o2rzoWj8olZUlG1oyOuaor4hlnUy2Wk3dzbAnEowu7HdQeTRYS6fq0eoxxQyW1zMuy6jkBDjIIzj8TVe0fW9EtUtX09L23iG1ZIJNrbfdT1NAGzp2o2+qWguLcttyVZWGGVh1BHrRVXRLqwu0uZLOJoZTJuuInBDBz6iigDVooooAKKKKACiiigArJ1rTJrxre7snWO9tWLRlvusD1U/WtaigDCbUtckjMUei+XcEY8x51Man19/pTRoktr4ZvLOM+feXCs8jZxvc/Wt+igCrpsT2+l2kMq7ZI4URhnOCFANVvENpPfaFdW1sm+Zwu1cgZ+YHqfpWnRQBhQ3+uRQxx/wDCPk7VC5+2JzijU7e/1TTrEmy8mdLtJJIvNVtqgnnPQ9q3aKAKGr6aup2DQ7tkqnfDIOqOOhqn4Ysr2y0+db+PZPJcNIRuBzkDnj3zW3RQBleILW7vrBbO1QkTSKsz7gNkeck89fwqyuk6cqhRYW2AMcxL/hVyigDm7TQpm07UtIuEKWjSlrWUEHAJyOM54IH5mpLe912zhW2uNK+1SINqzRTKFcepz0roKKAMbS9LmD3l3qWxrm8G140OVRMYC1Usk1fQUNktkb+0UnyZEkCsoJ6EGukooAw7OyvrzV11TUYlt/JQpb26uGK56sSOM4qpYLrOlT36x6P9ojnunlV/tKJwTxxXT0UAZUEt/qKT219pjWcUkTL5guFc5PGMDp1PPtVOzm1nSrdbOXTjepH8sc8UoG4dsg9DXQ0UAc9b6PdXsuoXd+BbSXkQiWKNtxjA6EnueBS2t3rdhbpaz6Ubpo1CLNFMoDgdMg8iugooAx9G0+5hur3UL0JHPdspMKHIQKMDnuaK2KKAP//Z\" />\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These images are for your reference: \\nPaper Title:  The language of proteins: NLP, machine learning & protein sequences, <img width=\"80%\" height=\"80\" src=\"data:image/jpeg;base64,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\" />\\nPaper Title:  Chapter 6 Cell Systems Learning the protein language: Evolution, structure, and function, <img width=\"80%\" height=\"80\" src=\"data:image/jpeg;base64,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\" />'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\n2\\n3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\\n\".join([\"1\", \"2\", \"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='installation unsurprisingly leads to various disease phenotypes, most notably cancer, neurodegeneration, and aging (Xu et al., 2018; Zhong et al., 2023). For example, while wild-type STAT3 is a standard transcription factor for eukaryotic cellular function, the phosphorylation of STAT3 at key residues drives the tumorigenesis and metastasis of numerous cancers (Rebe et al., 2013; Lin et al., 2020). As a result, it is critical to capture the unique features of protein sequences that are post-translationally modified.  \\nThe sequential nature of protein sequences, alongside their hierarchical semantics, makes them a natural target for language modeling. Recently, protein language models (pLMs), such as the state-of-the-art ESM-2 and ProtT5 models, have been pre-trained on over 200 million natural protein sequences to generate latent embeddings that accurately encode relevant physicochemical and functional information (Lin et al., 2023; Elnaggar et al., 2022). Autoregressive pLMs, such as ProGen and ProtGPT2, have generated diverse protein sequences with validated functional capacities (Madani et al., 2023; Ferruz et al., 2022). Our group has specifically utilized pLM embeddings to _de novo_ derive peptides that can bind and degrade diverse target proteins, whether conformationally ordered or not (Palepu et al., 2022; Brixi et al., 2023; Bhat et al., 2023; Chen et al., 2023b). Arguably the most notable usage of protein sequence embeddings, however, has been for the accurate downstream prediction of protein tertiary structure, as evidenced by the success of models such as AlphaFold2 and ESMFold (Jumper et al., 2021; Lin et al., 2023). In spite of these incredible advances, _none_ of these attention-based models encompass PTM residues as a part of their training or inference procedures, essentially precluding modeling of PTM effects in both sequence and structural space.  \\nIn this work, we fill this major gap in protein sequence modeling, by training the first pLM to explicitly encompass PTM information. Instead of using the standard Transformer architecture, we employ recent innovations in state space modeling (SSMs), specifically the Mamba model, which utilizes hardware-aware primitives to overcome the quadratic time complexity of the standard attention mechanism (Gu and Dao, 2023). For training, rather than relearning the semantics and evolutionary statistics of protein sequences, we curate a comprehensive, experimentally-validated dataset of post-translationally modified protein sequences (UniProt-Consortium, 2020), and leverage a fusion module that dynamically combines the embeddings of PTM-Mamba and ESM-2 in a gated mechanism. Our results demonstrate that by imbuing PTM information into expressive, pre-trained pLM latent spaces, we distinguish the latent representations of PTM sequences from their wild-type counterparts and effectively improve performance on downstream PTM-specific supervised training tasks, including phosphorylation site prediction, non-histone acetylation site prediction, disease association, and druggability. To the best of our knowledge, our resultant **PTM-Mamba** model is the first and only pLM that can input both wild-type and modified protein sequences to derive unique and accurate latent embeddings. As a result, this work motivates the usage of PTM-Mamba to both model and design the complete set of proteoforms found in nature.', metadata={'doc_id': 'f229433f-284b-4957-a817-fafc082bbddd', 'title': 'bioRxiv preprint doi: [https://doi.org/10.11011/2024.02.28.581983](https://doi.org/10.11011/2024.02.28.581983); this version posted February 29, 2024. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under aDC-BY-NC-ND 4.0 International license.'}),\n",
       " Document(page_content='installation unsurprisingly leads to various disease phenotypes, most notably cancer, neurodegeneration, and aging (Xu et al., 2018; Zhong et al., 2023). For example, while wild-type STAT3 is a standard transcription factor for eukaryotic cellular function, the phosphorylation of STAT3 at key residues drives the tumorigenesis and metastasis of numerous cancers (Rebe et al., 2013; Lin et al., 2020). As a result, it is critical to capture the unique features of protein sequences that are post-translationally modified.  \\nThe sequential nature of protein sequences, alongside their hierarchical semantics, makes them a natural target for language modeling. Recently, protein language models (pLMs), such as the state-of-the-art ESM-2 and ProtT5 models, have been pre-trained on over 200 million natural protein sequences to generate latent embeddings that accurately encode relevant physicochemical and functional information (Lin et al., 2023; Elnaggar et al., 2022). Autoregressive pLMs, such as ProGen and ProtGPT2, have generated diverse protein sequences with validated functional capacities (Madani et al., 2023; Ferruz et al., 2022). Our group has specifically utilized pLM embeddings to _de novo_ derive peptides that can bind and degrade diverse target proteins, whether conformationally ordered or not (Palepu et al., 2022; Brixi et al., 2023; Bhat et al., 2023; Chen et al., 2023b). Arguably the most notable usage of protein sequence embeddings, however, has been for the accurate downstream prediction of protein tertiary structure, as evidenced by the success of models such as AlphaFold2 and ESMFold (Jumper et al., 2021; Lin et al., 2023). In spite of these incredible advances, _none_ of these attention-based models encompass PTM residues as a part of their training or inference procedures, essentially precluding modeling of PTM effects in both sequence and structural space.  \\nIn this work, we fill this major gap in protein sequence modeling, by training the first pLM to explicitly encompass PTM information. Instead of using the standard Transformer architecture, we employ recent innovations in state space modeling (SSMs), specifically the Mamba model, which utilizes hardware-aware primitives to overcome the quadratic time complexity of the standard attention mechanism (Gu and Dao, 2023). For training, rather than relearning the semantics and evolutionary statistics of protein sequences, we curate a comprehensive, experimentally-validated dataset of post-translationally modified protein sequences (UniProt-Consortium, 2020), and leverage a fusion module that dynamically combines the embeddings of PTM-Mamba and ESM-2 in a gated mechanism. Our results demonstrate that by imbuing PTM information into expressive, pre-trained pLM latent spaces, we distinguish the latent representations of PTM sequences from their wild-type counterparts and effectively improve performance on downstream PTM-specific supervised training tasks, including phosphorylation site prediction, non-histone acetylation site prediction, disease association, and druggability. To the best of our knowledge, our resultant **PTM-Mamba** model is the first and only pLM that can input both wild-type and modified protein sequences to derive unique and accurate latent embeddings. As a result, this work motivates the usage of PTM-Mamba to both model and design the complete set of proteoforms found in nature.', metadata={'doc_id': '777a9614-0b04-4c16-8f29-c39b734af002', 'title': 'bioRxiv preprint doi: [https://doi.org/10.11011/2024.02.28.581983](https://doi.org/10.11011/2024.02.28.581983); this version posted February 29, 2024. The copyright holder for this preprint (which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under aDC-BY-NC-ND 4.0 International license.'}),\n",
       " Document(page_content='Purified L056 was concentrated to L8.6 mg ml-1 in 30 mmHgP5 pH 7.6, 150 mM NaCl, 0.5 mM TCEP. Crystals were distilled from sitting drop vapor diffusion experiments set at 20 degC with a 1:1 ratio of 200 ml protein and 200 ml solution (0.1 M CHES 9.5 pH, 30 %w/ PEG 3000). Diffraction data were collected from a single crystal at Beamline 8.3.1 at the Advanced Light Source. Data were processed using XDS5(tm) and a molecular replacement solution was identified using phaser(tm) with a ftosetta model of L056 as a search model. Significant translational non-crystallographic symmetry and differences with the search model resulted in maps that were initially hard to interpret. The initial model was improved using Refraczic jelly body refinement(r) using rebuilding using phenyl.autobould(r) and the CCP4 buccaneer_pipeline(r). The model was finalized and iteratively improved with multiple rounds of manual modification in Coot(tm) and refinement using phenyl.refine(r). The model is deposited as PDB accession 7RGR.', metadata={'doc_id': '86db6a37-8625-4d39-bdd8-070e96c9eb70', 'title': ' Large language models generate functional protein sequences across diverse families'}),\n",
       " Document(page_content='Evolution, structure, and function  \\nTristan Bepler  \\nBonnie Berger  \\n###### Abstract  \\nLanguage models have recently emerged as a powerful machine-learning approach for distilling information from massive protein sequence databases. From readily available sequence data alone, these models discover evolutionary, structural, and functional organization across protein space. Using language models, we can encode amino-acid sequences into distributed vector representations that capture their structural and functional properties, as well as evaluate the evolutionary fitness of sequence variants. We discuss recent advances in protein language modeling and their applications to downstream protein property prediction problems. We then consider how these models can be enriched with prior biological knowledge and introduce an approach for encoding protein structural knowledge into the learned representations. The knowledge distilled by these models allows us to improve downstream function prediction through transfer learning. Deep protein language models are revolutionizing protein biology. They suggest new ways to approach protein and therapeutic design. However, further developments are needed to encode strong biological priors into protein language models and to increase their accessibility to the broader community.', metadata={'doc_id': '8e7a8020-54f0-4b1e-be79-65c95b4b2920', 'title': ' Chapter 6 Cell Systems Learning the protein language: Evolution, structure, and function'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "import io\n",
    "import fitz\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import base64\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "def query(payload):\n",
    "\tAPI_URL = \"https://k05w2if7y9368qct.us-east-1.aws.endpoints.huggingface.cloud\"\n",
    "\tAPI_TOKEN = \"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\"\n",
    "\theaders = {\n",
    "\t\t\"Accept\" : \"application/json\",\n",
    "\t\t\"Authorization\": f\"Bearer {API_TOKEN}\",\n",
    "\t\t\"Content-Type\": \"application/json\" \n",
    "\t}\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\n",
    "def rasterize_paper(\n",
    "    pdf: Path,\n",
    "    outpath: Optional[Path] = None,\n",
    "    dpi: int = 96,\n",
    "    return_pil=False,\n",
    "    pages=None,\n",
    ") -> Optional[List[io.BytesIO]]:\n",
    "    \"\"\"\n",
    "    Rasterize a PDF file to PNG images.\n",
    "\n",
    "    Args:\n",
    "        pdf (Path): The path to the PDF file.\n",
    "        outpath (Optional[Path], optional): The output directory. If None, the PIL images will be returned instead. Defaults to None.\n",
    "        dpi (int, optional): The output DPI. Defaults to 96.\n",
    "        return_pil (bool, optional): Whether to return the PIL images instead of writing them to disk. Defaults to False.\n",
    "        pages (Optional[List[int]], optional): The pages to rasterize. If None, all pages will be rasterized. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Optional[List[io.BytesIO]]: The PIL images if `return_pil` is True, otherwise None.\n",
    "    \"\"\"\n",
    "\n",
    "    pillow_images = []\n",
    "    if outpath is None:\n",
    "        return_pil = True\n",
    "    try:\n",
    "        if isinstance(pdf, (str, Path)):\n",
    "            pdf = fitz.open(pdf)\n",
    "        if pages is None:\n",
    "            pages = range(len(pdf))\n",
    "        for i in pages:\n",
    "            page_bytes: bytes = pdf[i].get_pixmap(dpi=dpi).pil_tobytes(format=\"PNG\")\n",
    "            if return_pil:\n",
    "                pillow_images.append(page_bytes)#(io.BytesIO(page_bytes))\n",
    "            else:\n",
    "                with (outpath / (\"%02d.png\" % (i + 1))).open(\"wb\") as f:\n",
    "                    f.write(page_bytes)\n",
    "    except Exception:\n",
    "        pass\n",
    "    if return_pil:\n",
    "        return pillow_images\n",
    "\n",
    "def nougat(image):\n",
    "    output = query({\"inputs\":base64.b64encode(image).decode(\"utf-8\"), \n",
    "\t\t\t\t\t\"fix_markdown\":True,\n",
    "\t\t\t\t\t\"parameters\": {\"max_new_tokens\" : 3584, \n",
    "\t\t\t\t\t\t\t\t\"return_dict_in_generate\":True, \n",
    "\t\t\t\t\t\t\t\t\"output_scores\":True}})\n",
    "    return output['generated_text']\n",
    "\n",
    "def extract_markdown(filepath):\n",
    "    results = []\n",
    "    images = rasterize_paper(pdf=filepath, return_pil=True)\n",
    "    for image in images:\n",
    "        markdown = nougat(image)\n",
    "        results.append(markdown)\n",
    "    return results\n",
    "\n",
    "def extract_image_table(file_path, images_path):\n",
    "    loader = UnstructuredPDFLoader(file_path = file_path, \n",
    "                                extract_image_block_types=[\"Image\", \"Table\"],\n",
    "                                extract_image_block_to_payload=False,             \n",
    "                                extract_image_block_output_dir=images_path)\n",
    "    data = loader.load()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory behind Graph Convolutional Networks (GCNs) is grounded in the concept of learning representations of graph-structured data by leveraging the spectral properties of graphs. GCNs are a type of Graph Neural Networks (GNNs) that use a graph filter to aggregate information from a node's neighbors and apply a nonlinear transformation to learn node representations.\n",
      "\n",
      "The spectral properties mentioned in the context include Spectral Smoothness (SS) and Maximum Frequency Response (MFR). SS refers to the smoothness of the graph filter's response to the graph's eigenvalues, characterized by the spectral Lipschitz constant $C_{\\lambda}$. MFR defines the maximum response of the graph filter to the highest eigenvalue.\n",
      "\n",
      "GCNs construct layers by composing a graph filter with a nonlinear mapping, as shown in Lemma 1. The graph filter is a polynomial function of the adjacency matrix's eigenvalues, and the nonlinear mapping is typically a pointwise nonlinearity like ReLU. The stability of GCNs is analyzed by bounding the difference in outputs for two graphs with perturbed node features or edges, as shown in inequality (5).\n",
      "\n",
      "The Lipschitz constant $C_{f}$ of a GCN is derived in Lemma 2, which provides a measure of the network's stability with respect to perturbations in the input graphs. This constant is calculated based on the SS and MFR terms and is used to ensure that the GCN's output does not change drastically for small changes in the input graph.\n",
      "\n",
      "In summary, the theory behind GCNs involves understanding and leveraging the spectral properties of graphs to construct stable and transferable GNNs that can effectively learn representations of graph-structured data.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def convert_to_latex(text):\n",
    "    # Step 1: Convert all double backslashes to single backslashes\n",
    "    text = text.replace('\\\\\\\\', '\\\\')\n",
    "\n",
    "    # Step 2: Convert \\( ... \\) into $ ... $\n",
    "    # This regex matches expressions within \\( and \\), replacing them with $\n",
    "\n",
    "    # Define the pattern to find and replace\n",
    "    pattern = r\"\\\\\\((.*?)\\\\\\)\"\n",
    "    # Replace the found pattern with the new format\n",
    "    converted_text = re.sub(pattern, r\"$\\1$\", text)\n",
    "\n",
    "    # Define the pattern to find and replace\n",
    "    pattern = r\"\\\\\\[(.*?)\\\\\\]\"\n",
    "    # Replace the found pattern with the new format\n",
    "    converted_text = re.sub(pattern, r\"$\\1$\", converted_text)\n",
    "\n",
    "    # converted_text = re.sub(r'\\\\\\((.*?)\\\\\\)', lambda m: f\"${m.group(1)}$\", text)\n",
    "    # converted_text = re.sub(r'\\\\\\[(.*?)\\\\\\]', lambda m: f\"${m.group(1)}$\", text)\n",
    "    return converted_text\n",
    "\n",
    "text = \"\"\"The theory behind Graph Convolutional Networks (GCNs) is grounded in the concept of learning representations of graph-structured data by leveraging the spectral properties of graphs. GCNs are a type of Graph Neural Networks (GNNs) that use a graph filter to aggregate information from a node's neighbors and apply a nonlinear transformation to learn node representations.\n",
    "\n",
    "The spectral properties mentioned in the context include Spectral Smoothness (SS) and Maximum Frequency Response (MFR). SS refers to the smoothness of the graph filter's response to the graph's eigenvalues, characterized by the spectral Lipschitz constant \\(C_{\\lambda}\\). MFR defines the maximum response of the graph filter to the highest eigenvalue.\n",
    "\n",
    "GCNs construct layers by composing a graph filter with a nonlinear mapping, as shown in Lemma 1. The graph filter is a polynomial function of the adjacency matrix's eigenvalues, and the nonlinear mapping is typically a pointwise nonlinearity like ReLU. The stability of GCNs is analyzed by bounding the difference in outputs for two graphs with perturbed node features or edges, as shown in inequality (5).\n",
    "\n",
    "The Lipschitz constant \\(C_{f}\\) of a GCN is derived in Lemma 2, which provides a measure of the network's stability with respect to perturbations in the input graphs. This constant is calculated based on the SS and MFR terms and is used to ensure that the GCN's output does not change drastically for small changes in the input graph.\n",
    "\n",
    "In summary, the theory behind GCNs involves understanding and leveraging the spectral properties of graphs to construct stable and transferable GNNs that can effectively learn representations of graph-structured data.\"\"\"\n",
    "print(convert_to_latex(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The theory behind Graph Convolutional Networks (GCNs) is grounded in the concept of learning representations of graph-structured data by leveraging the spectral properties of graphs. GCNs are a type of Graph Neural Networks (GNNs) that use a graph filter to aggregate information from a node's neighbors and apply a nonlinear transformation to learn node representations.\\n\\nThe spectral properties mentioned in the context include Spectral Smoothness (SS) and Maximum Frequency Response (MFR). SS refers to the smoothness of the graph filter's response to the graph's eigenvalues, characterized by the spectral Lipschitz constant \\\\(C_{\\\\lambda}\\\\). MFR defines the maximum response of the graph filter to the highest eigenvalue.\\n\\nGCNs construct layers by composing a graph filter with a nonlinear mapping, as shown in Lemma 1. The graph filter is a polynomial function of the adjacency matrix's eigenvalues, and the nonlinear mapping is typically a pointwise nonlinearity like ReLU. The stability of GCNs is analyzed by bounding the difference in outputs for two graphs with perturbed node features or edges, as shown in inequality (5).\\n\\nThe Lipschitz constant \\\\(C_{f}\\\\) of a GCN is derived in Lemma 2, which provides a measure of the network's stability with respect to perturbations in the input graphs. This constant is calculated based on the SS and MFR terms and is used to ensure that the GCN's output does not change drastically for small changes in the input graph.\\n\\nIn summary, the theory behind GCNs involves understanding and leveraging the spectral properties of graphs to construct stable and transferable GNNs that can effectively learn representations of graph-structured data.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_latex(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$C_{f}$'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the re library in Python to convert LaTeX from \\( ... \\) to $ ... $\n",
    "import re\n",
    "\n",
    "# Define the original LaTeX expression\n",
    "latex_expression = r\"\\(C_{f}\\)\"\n",
    "\n",
    "# Define the pattern to find and replace\n",
    "pattern = r\"\\\\\\((.*?)\\\\\\)\"\n",
    "\n",
    "# Replace the found pattern with the new format\n",
    "converted_expression = re.sub(pattern, r\"$\\1$\", latex_expression)\n",
    "\n",
    "converted_expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$C\\_{\\lambda}\\)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "original_string = \"\\\\(C\\_{\\\\lambda}\\\\)\"\n",
    "new_string = re.sub(r'\\\\(\\(|\\\\)', r'$', original_string)\n",
    "print(new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a string with \\\\ backslashes\n"
     ]
    }
   ],
   "source": [
    "print(original_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This function will be deprecated in a future release and `unstructured` will simply use the DEFAULT_MODEL from `unstructured_inference.model.base` to set default model name\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='nature biotechnology\\n\\nArticle\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\nLarge language models generate functional protein sequences across diverse families\\n\\nReceived: 12 July 2022\\n\\nAccepted: 17 November 2022\\n\\n1,2 , Ben Krause1,10, Eric R. Greene3,10, Subu Subramanian4,5, Ali Madani Benjamin P. Mohr6, James M. Holton Zachary Z. Sun6, Richard Socher1, James S. Fraser3 & Nikhil Naik 7,8,9, Jose Luis Olmos Jr.3, Caiming Xiong1, 1\\n\\nPublished online: 26 January 2023\\n\\n®\\n\\nCheck for updates\\n\\nDeep-learning language models have shown promise in various biotechnological applications, including protein design and engineering. Here we describe ProGen, a language model that can generate protein sequences with a predictable function across large protein families, akin to generating grammatically and semantically correct natural language sentences on diverse topics. The model was trained on 280 million protein sequences from >19,000 families and is augmented with control tags specifying protein properties. ProGen can be further fine-tuned to curated sequences and tags to improve controllable generation performance of proteins from families with sufficient homologous samples. Artificial proteins fine-tuned to five distinct lysozyme families showed similar catalytic efficiencies as natural lysozymes, with sequence identity to natural proteins as low as 31.4%. ProGen is readily adapted to diverse protein families, as we demonstrate with chorismate mutase and malate dehydrogenase.\\n\\nTraditional methods for protein engineering perform iterative mutagenesis and selection of natural protein sequences to identify proteins with desired functional and structural properties. By con- trast, rational or de novo protein design methods aim to improve the efficiency and precision of creating novel proteins with desired prop- erties. Structure-based de novo design methods1–5 employ simula- tions grounded in biophysical principles, whereas coevolutionary methods6–10 build statistical models from evolutionary sequence data to specify novel sequences with desired function or stability. Both structural and coevolutionary approaches are not without limitations. Structural methods rely on scarce experimental structure data and difficult or intractable biophysical simulations3,11. Coevolutionary statistical models are tailored to specific protein families, frequently rely on multiple sequence alignments, and do not operate well in space outside of the defined multiple sequence alignment11. Recently, deep\\n\\nneural networks have shown promise as generative and discriminative models for protein science and engineering12–20. Their ability to learn complex representations could be essential to effectively exploit an exponentially growing source of diverse and relatively unannotated protein data—public databases containing millions of raw unaligned protein sequences21–23.\\n\\nInspired by the success of deep-learning-based natural language models trained on large text corpora that generate realistic text with varied topics and sentiments24–28, we developed ProGen, a protein language model trained on millions of raw protein sequences that generates artificial proteins across multiple families and functions. While prior work has shown that natural-language-inspired statis- tical representations of proteins are useful for protein informatics tasks such as stability prediction, remote homology detection and secondary structure prediction11,29–31, we show that the latest advances\\n\\n1Salesforce Research, Palo Alto, CA, USA. 2Profluent Bio, San Francisco, CA, USA. 3Department of Bioengineering and Therapeutic Sciences, University of California, San Francisco, San Francisco, CA, USA. 4Department of Molecular and Cell Biology, University of California, Berkeley, Berkeley, CA, USA. 5Howard Hughes Medical Institute, University of California, Berkeley, Berkeley, CA, USA. 6Tierra Biosciences, San Leandro, CA, USA. 7Molecular Biophysics and Integrated Bioimaging Division, Lawrence Berkeley National Laboratory, Berkeley, CA, USA. 8Stanford Synchrotron Radiation Lightsource, SLAC National Accelerator Laboratory, Menlo Park, CA, USA. 9Department of Biochemistry and Biophysics, University of California, San Francisco, San Francisco, CA, USA. 10These authors contributed equally: Ben Krause and Eric R. Greene. e-mail: ali@madani.ai; nnaik@salesforce.com\\n\\nNature Biotechnology | Volume 41 | August 2023 | 1099–1106\\n\\n1099\\n\\nArticle\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\na\\n\\nControl tag(s) Model Generated english sentence Politics Sports English language model The Red Sox defeated the Yankees at Fenway Review 5 This knife is excellent for slicing meat Review 1 This knife is poorly made, not sharp at all!\\n\\nVoting for the presidential election has begun\\n\\nb\\n\\nControl tag(s) Model Generated protein sequence Immunoglobulin Chorismate mutase Glucosaminidase Phage Phage lysozyme Protein language model DIQMTQSPASLS ... PKSFNRNEC MSNTELELLRQK ... KEKAGLELQ YIEKYNAIAERHK ... RHKLNRFDG NIDFGFICELEGF ... ADLLESSMR\\n\\n* — (oe ¢ Pete\\n\\nc\\n\\nd\\n\\ne\\n\\nan\\n\\n™~\\n\\nUniversal protein sequence dataset\\n\\n{\\n\\n|\\n\\n\\\\ 1 nnennnnr, Trainin. ( in» — | NS TS\\n\\nTraining\\n\\nProtein language model\\n\\n;\\n\\nGeneration Control tag for protein family f\\n\\nantificial {\\n\\nArtificial proteins of protein family f\\n\\n1\\n\\n1\\n\\n‘\\n\\n! -\"\\n\\n}\\n\\n1\\n\\nUniversal protein sequence dataset\\n\\nTraining: Negative log likelihood minimization  Next amino acid prediction  a1  a2 a3  a4  ...  Transformer decoder  c Control  tag  a1 a2 a3 Amino acids  ...  6 3 k c o b r e d o c e D     l     1     k c o b r e d o c e D  l     Feed forward block  Multi-head self-attention  ...  Feed forward block  Multi-head self-attention \\n\\nNatural proteins  280M sequences >19K Pfam families   Lysozymes  56K sequences 5 Pfam families  a1  c Control  tag \\n\\nLysozymes \\n\\nFig. 1 | Artificial protein generation with conditional language modeling. a, Conditional language models are deep neural networks that can generate semantically and grammatically correct, yet novel and diverse natural language text, steerable using input control tags that govern style, topic and other entities. b,c, Analogous to natural language models, we develop ProGen, a conditional protein language model (b) that generates diverse artificial protein sequences across protein families based on input control tags (c). d, ProGen is trained using\\n\\na large, universal protein sequence dataset of 280 million naturally evolved proteins from thousands of families, of which five diverse lysozyme families are experimentally characterized in this study. e, ProGen is a 1.2-billion-parameter neural network that is based on the Transformer architecture, which uses a self- attention mechanism for modeling comprehensive residue–residue interactions. ProGen is trained to generate artificial sequences by minimizing the loss over the next amino acid prediction problem on the universal protein sequence dataset.\\n\\nin deep-learning-based language modeling can be adopted to gener- ate artificial protein sequences, from scratch, that function as well as natural proteins.\\n\\nProGen is iteratively optimized by learning to predict the probabil- ity of the next amino acid given the past amino acids in a raw sequence, with no explicit structural information or pairwise coevolutionary assumptions. Trained in this unsupervised manner from a large, varied protein sequence database (Supplementary Table 1), ProGen learns a universal, domain-independent representation of proteins that sub- sumes local and global structure motifs, analogous to natural language models learning semantic and grammatical rules. After training, Pro- Gen can be prompted to generate full-length protein sequences for any protein family from scratch, with a varying degree of similarity to natural proteins. In the common case where some sequence data from a protein family is available, we can use the technique of fine tuning pretrained language models32–35 with family-specific sequences to further improve the ability of ProGen to capture the distribution of local sequence neighborhoods corresponding to the protein family.\\n\\nProGen is a 1.2-billion-parameter neural network trained using a publicly available dataset of 280 million protein sequences. A key component of ProGen is conditional generation28,36–38, that is, sequence generation controlled by property tags (for example, Protein Family: Pfam ID PF16754, Pesticin) provided as input to the language model. In the case of natural language, these control tags may be style, top- ics, dates and other entities (Fig. 1a). For proteins, the control tags are properties such as protein family, biological process and molecular function, which are available for a large fraction of sequences in public protein databases (Fig. 1b and Supplementary Fig. 1).\\n\\nResults We experimentally evaluated the ability of ProGen to generate func- tional artificial amino acid sequences by testing its generations across five distinct protein families from the lysozyme clan23,39 (Supplemen- tary Table 2). The protein families contain substantial sequence diver- sity (Supplementary Table 3) with average sequence length varying between 84–167 across families. The sequences also show large struc- tural diversity and multiple structural folds (Supplementary Fig. 2). As a whole, this represents a challenging design space for a model that is not constrained in generation to local sequence neighborhoods near known functional wild types and also not provided with structural pri- ors. We collected a dataset of 55,948 sequences from these five families from Pfam and UniprotKB sources for obtaining positive controls and for fine tuning32–35 ProGen.\\n\\nAfter fine tuning ProGen using the curated lysozyme data- set, we generated one million artificial sequences using ProGen by providing the Pfam ID for each family as a control tag. Our artificial lysozymes span the sequence landscape of natural lysozymes (Fig. 2a) across five families that contain diverse protein folds, active site architectures and enzymatic mechanisms40,41. As our model can generate full-length artificial sequences within milliseconds, a large database can be created to expand the plausible sequence diversity beyond natural libraries (Supplementary Table 3). Although artifi- cial sequences may diverge from natural sequences purely from a sequence identity calculation, (Fig. 2b and Supplementary Fig. 3), they demonstrate similar residue position entropies when forming separate multiple sequence alignments of natural and artificial proteins within each family (Fig. 2c). This indicates that the model has captured\\n\\nNature Biotechnology | Volume 41 | August 2023 | 1099–1106\\n\\n1100\\n\\nArticle\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\na  Glucos- aminidase  Glycoside  hydrolase  Pesticin  Transglycosylase  Phage lysozyme \\n\\nb\\n\\nArtificial proteins: one million generations  0.06  0.04  0.02  0  20%  40%  60%  80%  Max ID with any known natural protein  100% \\n\\ny t i s n e D\\n\\nNatural proteins Artificial proteins\\n\\nd\\n\\nDNA synthesis\\n\\nIn vitro translation\\n\\nProtein purification\\n\\nAssay activity\\n\\n: =m (08) ia\" @ —_> — 9\\n\\ne\\n\\n30  20  10  High expression  Low/no expression  60%  60%  64%  77%  84%  0 \\n\\ns n e t o r p d e s s e r p x e f o r e b m u N\\n\\ni\\n\\ns n e t o r p d e s s e r p x e f o r e b m u N\\n\\ni\\n\\n100\\n\\n80\\n\\n60\\n\\n40\\n\\n20\\n\\n72%\\n\\n72%\\n\\n72%\\n\\nc\\n\\n——\\n\\nNatural proteins\\n\\n——\\n\\nArtificial proteins\\n\\nPhage lysozyme  .  q e s     l a r u t a N  y t i l i  b a i r a v  0.5  0  0  20  40  60  80  100  0.5  0  Transglycosylas  .  q e s     l a r u t a N  y t i l i  b a i r a v  0.5  0.50  0.25  0  0  0  20  40  60  Glycoside hydrolase  .  q e s     l a r u t a N  y t i l i  b a i r a v  0.5  0  0  20  40  Glucosaminidase  60  80  0.50  0.25  0  .  q e s     l a r u t a N  .  q e s     y t i l i  b a i r a v  y t i l i  0.5  0  0.5  0  25  50  75  Pesticin  100  125  0.5  0  0.5  v a r i a b  A r t i f i c a l  i  i l i t y     s e q  .  v a r i a b  A r t i f i c a l  i  i l i t y     s e q  .  v a r i a b  A r t i f i c a l  i  i l i t y     s e q  .  v a r i a b  A r t i f i c a l  i  i l i t y     s e q  .  v a r i a b  A r t i f i c a l  i    \\n\\nl a r u t a N\\n\\nb a i r a v\\n\\ni l i t y\\n\\ns e q\\n\\n0\\n\\n0\\n\\nom\\n\\nTo\\n\\n0\\n\\n.\\n\\n40–50%\\n\\n50–60%\\n\\n60–70%\\n\\n70–80%\\n\\n80–90%\\n\\nArtificial proteins: maximum ID with any known natural protein\\n\\nAll artificial proteins Natural proteins\\n\\n0\\n\\n25\\n\\n50\\n\\n75\\n\\n100\\n\\n125\\n\\nPosition in multiple sequence alignment\\n\\n150\\n\\nFig. 2 | Generated artificial antibacterial proteins are diverse and express well in our experimental system. a, When analyzed using t-distributed stochastic neighbor embedding (t-SNE) as a dimensionality reduction technique for visualization purposes, artificial sequences from our model are shown to span the landscape of natural proteins from five lysozyme families. Each point represents a natural or generated sequence embedded in a two-dimensional t-SNE space. b, With sufficient sampling, ProGen can generate sequences that are highly dissimilar from natural proteins. Max ID measures the maximum identity of an\\n\\nartificial protein with any publicly available natural protein. c, Artificial proteins maintain similar evolutionary conservation patterns as natural proteins across families. Plots demonstrate the variability at each aligned position for a library of proteins. Conserved positions are represented as curve dips. seq., sequence. d, From our generated proteins, we select one hundred proteins for synthesis and characterization in our experimental setup. e, Artificial proteins express well even with increasing dissimilarity from nature (40–50% max ID) and yield comparable expression quality to one hundred representative natural proteins.\\n\\nevolutionary conservation patterns without training on explicit alignment information such as with Potts models42, as implemented in direct coupling analysis7,43–46.\\n\\nTo experimentally evaluate ProGen performance across a range of sequence divergences from natural proteins, we selected one hundred sequences filtered on the basis of generation quality and diversity to natural sequences, measured as top-hit identities (‘max ID’) to any protein in our training dataset containing 280 million proteins, which is primarily composed of UniParc21 (Supplementary Fig. 4). Our selected proteins included 100 artificial sequences (Supplementary Table 2), with a minimum of 8 proteins from each protein family. The average sequence length for artificial proteins varies between 93–179 across families, comparable to natural lysozymes in our curated dataset from Pfam. Artificial proteins included specific amino acids and pairwise interactions never before observed in aligned positions in lysozyme family-specific alignments (Supplementary Tables 4 and 5). We also selected a positive control group from the 55,948 curated lysozyme sequences. We clustered the natural sequences with MMseqs247 and\\n\\nchose roughly 20 cluster-representative sequences from each of the five families.\\n\\nTo evaluate function, full-length genes were synthesized and puri- fied via cell-free protein synthesis and affinity chromatography. In the positive control set of 100 natural proteins, 72% were well expressed as measured by chromatography peaks and band visualization. The ProGen-generated proteins express equally well (72/100 total) across all bins of sequence identity to any known natural protein (max ID 40–90%; Fig. 2e). In addition, we designed artificial proteins using bmDCA7, a statistical model that is based on direct coupling analysis, which explicitly approximates first and second-order residue depend- encies. Starting from their publicly available code, we tried to make the bmDCA model converge on the same sequences as ProGen and using additional alignment information and searched over a wide range of hyperparameters. bmDCA was unable to fit three out of the five lysozyme families, and exhibited 60% detectable expression (30/50 proteins) for the remaining two protein families. These results indicate that ProGen can generate artificial proteins that are structurally well\\n\\nNature Biotechnology | Volume 41 | August 2023 | 1099–1106\\n\\n1101\\n\\nArticle\\n\\nfolded for proper expression as compared to a batch of natural pro- teins, even when sequence alignment size and quality limit the success of alternative approaches.\\n\\nNext we examined activity on the basis of quench release of fluorescein-labeled Micrococcus lysodeikticus cell wall (Molecular Probes EnzChek Lysozyme kit) using 90 randomly chosen proteins out of each expressed set of 100. Proteins were prepared in 96-well plate format to extract fluorescence curves over time (Fig. 3a). Hen egg white lysozyme (HEWL), a naturally evolved exemplar protein, was meas- ured as positive control, in addition to ubiquitin as negative control. Proteins that generated fluorescence one standard deviation above the maximum fluorescence of any negative control were considered functional. Among our artificial proteins, 73% (66/90) were functional and exhibited high levels of functionality across families (Fig. 3c). The representative natural proteins exhibited similar levels of functionality with 59% (53/90) of total proteins considered functional. None of the bmDCA artificial proteins exhibited a detectable level of functionality (Supplementary Fig. 5), which may be due to convergence, sampling, or other specific model run issues further highlighting the versatility of ProGen providing a potentially more robust alternative. These results indicate that ProGen generates protein sequences that not only can express well but also maintain enzymatic function for diverse sequence landscapes across protein families.\\n\\nIn addition to a binary value for functionality, we calculated a relative activity score with respect to HEWL for the in vitro assay. Our artificial proteins match activity levels of natural proteins even at lower levels of sequence identity to any known natural protein, (Fig. 3b and Supplementary Fig. 6). Notably a small number of proteins, both within the natural and artificial proteins, were within an order of magnitude of HEWL, which was substantially more active than all negative controls. These highly active outliers demonstrate the potential for our model to generate sequences that may rival natural proteins that have been highly optimized through evolutionary pressures.\\n\\nFrom the 100 artificial proteins, we selected five proteins that spanned a wide range of max IDs (48–89%) to recombinantly express in Escherichia coli. Of these, only one, L008, generated no detectable expression (Supplementary Fig. 7). Two (L013 and L038) expressed robustly to inclusion bodies and were not pursued further. Two pro- teins, L056 (max ID 69.6%) and L070 (max ID 89.2%) expressed well and incurred bactericidal activities towards the E. coli BL21(DE3) strain used during overnight induction at 16 °C. Spent medium har- bored enzymatic activity, therefore, enzymes were purified from this material.\\n\\nWhile both enzymes purified as monomers at the expected size by size-exclusion chromatography, we also observed a defined later eluting (apparent lower molecular weight, likely owing to binding to the dextran component of the column) species for each enzyme that corresponded to full-length enzyme by SDS-PAGE (Supplementary Fig. 7). The KM values of both monomers were too weak to be meas- ured using a heterogeneous, fluorescein-labeled M. lysodeikticus cell wall substrate (Molecular Probes EnzChek Lysozyme kit); however, both monomers were active using a pseudo-first-order kinetic assay (Supplementary Fig. 8). By contrast, we could readily measure the KM values for the purified apparent lower molecular weight species, where both L056 and L070 were highly active and had comparable Michaelis–Menten parameters to HEWL (Fig. 3d). Taken together, L056 and L070 harbor potent catalytic activity and bactericidal capabilities that are comparable to HEWL, while diverging from their nearest known natural sequence by 53 and 18 amino acids, respectively. We also found that there is no bias to location or structural element to the mutations that diverge L056 and L070 from their respective nearest sequence homolog in nature. Differing residues are instead uniformly distrib- uted. Some mutations are even found within the active site cleft and within regions that influence conformational state (for L056). Despite having comparable enzymatic activities, L070 and L056 only share\\n\\nNature Biotechnology | Volume 41 | August 2023 | 1099–1106\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\n17.9% sequence ID. In sum, these results demonstrate that ProGen can generate artificial proteins with near native activity.\\n\\nNext, we examined the structural divergence of the artificial pro- teins. We determined a 2.5-Å resolution crystal of L056 (Fig. 3e and Supplementary Table 6). The global fold was similar to predictions, with a Cα root mean squared deviation (RMSD) of 2.9 Å from the backbone structure predicted by trRosetta and 2.3 Å RMSD from a wild-type T4 lysozyme structure48,49. The largest structural divergence occurs in the beta hairpin formed by residues 18–31. This region forms the bottom of the substrate-binding cleft50 and is part of a hinge binding motion that is important for substrate binding51. The structure of the M6I mutant of T4 lysozyme (Protein Data Bank (PDB) accession 150L) is used as a model of the ‘open’ state of this hinge and more closely resembles the structure of L056 (1.0 Å Cα RMSD). Alignment with a structure featur- ing a covalently trapped substrate (PDB accession 148L) reveals that the active site cleft is well formed with the key catalytic residue Glu15 (Glu 11 in T4L) and key substrate-binding residue Thr30 (Thr26 in T4L) correctly positioned. In addition, the hydrophobic core of L056 is well packed, with only two small packing voids of less than 5 Å3 in volume, which is typical for structures of this size52.\\n\\nTo examine whether ProGen could generate functional proteins in the ‘twilight zone’ sequence identity53 where two proteins are not assumed to share functional similarity54, we generated 95 new artifi- cial sequences with maximum sequence identities lower than 40% to any known natural protein for two lysozyme families (PF00959 and PF05838). Of the selected sequences, 78 out of the 89 (88%) expressed well and 24 out of the 78 (31%) were soluble (Supplementary Fig. 9). We purified six highly expressed proteins and found that they were all active, but with lower Michaelis–Menten activities than HEWL or the previously generated artificial proteins L056 and L070 (Fig. 3f, Sup- plementary Fig. 10, and Supplementary Table 7). The protein with the lowest sequence identity to a natural protein, D4 (31.4% ID to a protein from an Arcobacter nitrofigilis organism), had a kcat/KM of 20.2 M−1s−1, approximately 200-fold below HEWL. While the activity is substan- tially lower for these distant proteins, directed evolution could be employed to improve activity. Collectively, these results demonstrate a procedure for generating soluble, active proteins that are distant enough in sequence space that they might not be considered traditional sequence homologs.\\n\\nTo additionally compare across structural representations, we used AlphaFold2 (ref. 14) to predict the structure of functional artificial sequences. As in the crystal structure of L056, the predicted artificial structures roughly match known structures found in nature (Supple- mentary Fig. 11) including for low identity (<40%) artificial sequences. Trained on a universal protein sequence dataset spanning many families, ProGen designs proteins from any family when provided with the corresponding control tag as input. To explore this capability beyond the lysozyme clan, we evaluated the performance of ProGen in generating and predicting functional full-length sequences from families where other methods have previously been applied: choris- mate mutase (CM)7 and malate dehydrogenase (MDH). Generated proteins exhibit similar conservation patterns to natural sequence libraries (Fig. 4a,d). After aligning the generations to a sequence with known structure (Fig. 4b,e), we observed that the conserved positions in generated sequences correlate with ligand-binding and buried resi- dues. Using previously published sequences and their experimentally measured assay data for CM7 and MDH55 proteins, we also evaluated the concordance of the ProGen model likelihood for these sequences to their relative activity and compared it with the generative methods used in the original studies—bmDCA7 and proteinGAN55. Specifically, we measured per-token log-likelihoods for artificial sequences using Pro- Gen and used them to predict if artificial sequences should function. On CM function data, ProGen log-likelihoods had an area under the curve (AUC) of 0.85, significantly better (P < 0.0001, two-tailed test, n = 1617) than bmDCA, which had an AUC of 0.78 (Fig. 4c). On MDH function\\n\\n1102\\n\\nArticle\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\na\\n\\n2,500  2,000  1,500  1,000  Artificial proteins Hen egg white lysozyme Negative control  500  0  100  200  300  Time (min) \\n\\ne c n e c s e r o u l F\\n\\nb\\n\\nNatural  10–3  Hen egg white lysozyme  10–2  10–1  100 \\n\\nArtificial 80–90% ID Artificial 70–80% ID Artificial 60–70% ID Artificial 50–60% ID Artificial 40–50% ID\\n\\nRelative activity\\n\\nc\\n\\n100\\n\\n5\\n\\nNatural proteins Artificial proteins  80  l a n o i t c n u f  60     t n e c r e P  40  20  0  Glu c osa m inid ase Glyc osid e hydrolase Transglyc osylase P ha g e lysozy m e  Pesticin \\n\\nd\\n\\n1.2  d e s a e l e r n e c s e r o u l F     i  )  1 – e m y z n e     1 – n m  i  (  1.0  0.8  0.6  0.4  0.2  HEWL L070 L056  0  0  0.1  0.2  0.3  0.4  0.5 \\n\\nFluorescein-labeled M. lysodeikticus cell wall (g l–1)\\n\\ne\\n\\nClosed\\n\\nSubstrate\\n\\nT26/30  E11/15  Open \\n\\nf\\n\\n1,000  )  1 – s  100     1 –  M  ( M K /     10     t a c k  1  0.1  HEWL  L056*  L070*  A5*  C9  D4  E11  MaxID (%):  69.6  89.2  39.1  35.7  31.4  38.7 \\n\\nFig. 3 | Artificial protein sequences are functional while reaching as low as 31% identity to any known protein, exhibit comparable catalytic efficiencies to a highly-evolved natural protein, and demonstrate similar structures to known natural folds. a, Artificial proteins bind well to substrates and exhibit high fluorescence responses over time (n = 90). For HEWL and negative (ubiquitin) controls, the minimum and maximum fluorescence range of n = 3 replicates are shown as bars. b, Artificial proteins remain active even while being dissimilar (40–50% max ID that is, top hit-identity) from known natural proteins. Outliers indicate high activity samples where relative activity is computed with respect to HEWL. Box plots are derived from n = 90, 23, 28, 22, 8, 9 samples for each category from top to bottom, respectively. Boxes display the median, first quartile and third quartile with whiskers which extend to 1.5× the inter-quartile range. c, Artificial proteins are functional across protein families. Functional is defined as a fluorescence one standard deviation above the maximum value of all negative controls. d, Michaelis–Menten kinetics of HEWL natural lysozyme (red) and two generated lysozymes (blue; L056 and L070) against cell wall\\n\\nsubstrate show comparable performance (n = 3 technical replicates where error bars represent standard deviation). e, We determined a 2.5-Å resolution crystal of L056 artificial lysozyme. A global overlay of L056 crystal structure with two representative T4 lysozyme conformations is shown with L056 presented in sky blue, ‘open’ conformation of M6I T4 lysozyme (PDB accession 150L) in dark red, ‘closed’ conformation of wild-type T4 lysozyme (PDB accession 3FA0) in orange, and substrate (PDB accession 148L) colored by element. Catalytic threonine (T30 in L056 and T26 in T4 lysozyme) and first catalytic glutamate (E15 in L056 and E11 in T4 lysozyme) are represented as sticks. f, Bars represent Michaelis– Menten kcat/KM constants derived for lysozyme variants demonstrating a range of catalytic activities across variants of varied maximal sequence IDs to known natural protein. Error bars represent propagated standard deviations derived from fitting procedure (n = 3 for A5, L056 and L070 technical replicates; n = 4 for C9 and E11 technical replicates; two biological replicates of each n = 4 technical replicates for D4). Asterisk denotes kcat/KM derived from initial rate analysis and unit converted (Supplementary Table 7).\\n\\ndata, ProGen log-likelihoods had an AUC of 0.94 (Fig. 4f), which was better than ProteinGAN discriminator scores, with an AUC of 0.87 (P < 0.1, two-tailed test, n = 56). In sum, the model likelihoods of ProGen\\n\\nare better aligned with experimentally measured assay data on two diverse protein datasets—CM and MDH—than the sequence-generation methods from original studies specifically tailored for these families.\\n\\nNature Biotechnology | Volume 41 | August 2023 | 1099–1106\\n\\n1103\\n\\nArticle\\n\\na\\n\\nChorismate mutase: natural proteins  y t i l i  1.0  b a b o r P  0.5  0  Chorismate mutase: artificial proteins  y t i l i  1.0  b a b o r P  0.5  0  7  11  14 15 18 21 27 28 35 36 39 51 52 55 66 77 80 81 84  88 \\n\\nd\\n\\nMalate dehydrogenase: natural proteins\\n\\n1.0  0.5 \\n\\ny t i l i\\n\\nb a b o r P\\n\\n0\\n\\nMalate dehydrogenase: artificial proteins\\n\\n1.0  0.5 \\n\\ny t i l i\\n\\nb a b o r P\\n\\n0\\n\\n10 13 30 41 55 91 95 97 104 119 130 131 133 158 162 184 186 192 260 288\\n\\nFig. 4 | Applicability of conditional language modeling to other protein systems. a,b, Using the appropriate control tag, our language model, ProGen, can generate sequences for distinct protein families. Here we show that ProGen can generate CM enzymes that exhibit a similar residue distribution to nature (a) and the conserved residues among generated sequences correlate to ligand-binding sites (b). c, The model likelihoods of ProGen can also accurately predict the functionality of CM variants from published data, slightly better\\n\\nTo understand the relative impact of the universal sequence data- set and of sequences from the protein family of interest on the genera- tion ability of ProGen, we perform two ablation studies using the CM and MDH experimentally measured assay data. First, we evaluated the performance of ProGen trained only with the universal sequence dataset. We measured per-token log-likelihoods for artificial sequences for this version of ProGen using control tags for CM and MDH. These likelihoods showed a significant drop in AUC of 0.18 for CM (P < 0.0001, two-tailed test, n = 1,617) and 0.08 for MDH (P < 0.1, two-tailed test, n = 56), as compared to fine-tuned ProGen when predicting if an arti- ficial sequence should function. Conversely, the ProGen architecture trained on CM and MDH protein sequences alone without the benefit of initial training on the universal sequence dataset also showed a sig- nificant drop in performance as compared to fine-tuned ProGen—the AUC reduced by 0.11 (P < 0.0001, two-tailed test, n = 1,617) and 0.04 (P < 0.05, two-tailed test, n = 56) on the CM and MDH data, respectively. These results indicate that both components of our training strat- egy—initial training on the universal sequence dataset and fine tun- ing on the protein family of interest—contribute significantly to final model performance. Training with the universal sequence dataset containing many protein families enables ProGen to learn a generic and transferable sequence representation that encodes intrinsic biologi- cal properties. Fine tuning on the protein family of interest steers this representation to improve generation quality in the local sequence neighborhood. Similar to the adaptability shown by neural networks trained on large datasets using transfer learning and fine tuning in natural language processing25,34,56 and computer vision57,58, protein language models have the potential to be a versatile tool for generating tailored proteins with desired properties. In Supplementary Fig. 12,\\n\\nNature Biotechnology | Volume 41 | August 2023 | 1099–1106\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\nb\\n\\nPDB: 1ECM\\n\\n\\n\\n]\\n\\nConserved positions in artificial sequences\\n\\nc\\n\\ne t a r e v i t i s o p e u r T\\n\\nProGen, AUC = 0.85 bmDCA, AUC = 0.78  0  0.5  1.0 \\n\\n1.0\\n\\n0.5\\n\\n0\\n\\nI\\n\\nLigand\\n\\nFalse positive rate\\n\\ne\\n\\nf\\n\\nPDB: 4MDH\\n\\n1.0\\n\\n\\n\\ne t a r e v i t i s o p e u r T\\n\\n0.5\\n\\nConserved positions in artificial sequences\\n\\n0\\n\\n0 ===\\n\\nProGen, AUC = 0.94 ProteinGAN, AUC = 0.87\\n\\ni\\n\\nLigand\\n\\n0\\n\\n0.5\\n\\n1.0\\n\\nFalse positive rate\\n\\nthan the coevolutionary bmDCA7 algorithm from the original study. d, ProGen can also generate MDH proteins that exhibit a similar residue distribution to nature. e, The conserved residues among generated sequences correlate to buried residues. f, The model likelihoods of ProGen are also accurate in predicting functionality of published variants of MDH, similar to the generative proteinGAN55 model used in the original study.\\n\\nthe distribution of available sequences for different protein families indicates there is a large portion of the protein universe where our current technique would be useful. We extrapolate that it may be pos- sible to successfully generate artificial proteins with functional activity without fine tuning, especially for larger protein families; however, it would likely do so at a small success rate. We did not attempt to experi- mentally test generated sequences without additional fine tuning in our study.\\n\\nDiscussion In conclusion, our study shows that a state-of-the-art transformer-based conditional language model trained only with evolutionary sequence data generates functional artificial proteins across protein families. Additional analyses suggest that our model has learned a flexible pro- tein sequence representation that can be applied to diverse families such as lysozymes, CM, and MDH. While we do not expect our language model to generate proteins that belong to a completely different dis- tribution or domain (for example, creating a new fold that catalyzes an unnatural reaction), it can substantially expand the space of protein sequences from those sampled by evolution. Combining biophysi- cal modeling with generative models could further help us explore data distributions that are completely distinct from those sampled by evolution17,59,60. Applications of our model could include generating synthetic libraries of highly likely functional proteins for discovery or iterative optimization. In combination with ever-increasing sources of sequence data and more expressive control tags, our work points to the potential for the use of deep-learning-based language models for precise de novo design of proteins to solve problems in biology, medicine, and the environment.\\n\\n1104\\n\\nArticle\\n\\nOnline content Any methods, additional references, Nature Portfolio reporting sum- maries, source data, extended data, supplementary information, acknowledgements, peer review information; details of author con- tributions and competing interests; and statements of data and code availability are available at https://doi.org/10.1038/s41587-022-01618-2.\\n\\nReferences 1. Koga, N. et al. Principles for designing ideal protein structures.\\n\\nNature 491, 222–227 (2012).\\n\\n2. Lin, Y.-R. et al. Control over overall shape and size in de novo designed proteins. Proc. Natl Acad. Sci. USA 112, E5478–E5485 (2015).\\n\\n3. Huang, P.-S., Boyken, S. E. & Baker, D. The coming of age of de novo protein design. Nature 537, 320–327 (2016). 4. Huang, P.-S. et al. De novo design of a four-fold symmetric\\n\\nTIM-barrel protein with atomic-level accuracy. Nat. Chem. Biol. 12, 29–34 (2016).\\n\\n5. Boyken, S. E. et al. De novo design of protein homo-oligomers with modular hydrogen-bond network–mediated specificity. Science 352, 680–687 (2016).\\n\\n6. Lapedes, A. S., Bertrand, G. G., LonChang, L. & Stormo, G. D. Correlated mutations in models of protein sequences: Phylogenetic and structural effects. Lect. Notes Monogr. Ser. 33, 236–256 (1999).\\n\\n7. Russ, W. P. et al. An evolution-based model for designing chorismate mutase enzymes. Science 369, 440–445 (2020).\\n\\n8. Hopf, T. A. et al. The EVcouplings Python framework for coevolutionary sequence analysis. Bioinformatics 35, 1582–1584 (2019).\\n\\n9. Morcos, F. et al. Direct-coupling analysis of residue coevolution captures native contacts across many protein families. Proc. Natl Acad. Sci. USA 108, E1293–E1301 (2011).\\n\\n10. Ovchinnikov, S., Kamisetty, H. & Baker, D. Robust and accurate prediction of residue-residue interactions across protein interfaces using evolutionary information. eLife 3, e02030 (2014).\\n\\n11. Alley, E. C., Khimulya, G., Biswas, S., AlQuraishi, M. & Church, G. M. Unified rational protein engineering with sequence-based deep representation learning. Nat. Methods 16, 1315–1322 (2019). 12. Wu, Z. et al. Signal peptides generated by attention-based neural\\n\\nnetworks. ACS Synth. Biol. 9, 2154–2161 (2020).\\n\\n13. Shin, J.-E. et al. Protein design and variant prediction using\\n\\nautoregressive generative models. Nat. Commun. 12, 2403 (2021). 14. Jumper, J. et al. Highly accurate protein structure prediction with\\n\\nAlphaFold. Nature 596, 583–589 (2021).\\n\\n15. Bryant, D. H. et al. Deep diversification of an AAV capsid protein by machine learning. Nat. Biotechnol. 39, 691–696 (2021). 16. Das, P. et al. Accelerated antimicrobial discovery via deep\\n\\ngenerative models and molecular dynamics simulations. Nat. Biomed. Eng. 5, 613–623 (2021).\\n\\n17. Anishchenko, I. et al. De novo protein design by deep network hallucination. Nature 600, 547–552 (2021).\\n\\n18. Moffat, L., Kandathil, S. M. & Jones, D. T. Design in the DARK: Learning deep generative models for De Novo Protein Design. Preprint at bioRxiv https://doi.org/10.1101/2022.01.27.478087 (2022).\\n\\n19. Ferruz, N., Schmidt, S. & Höcker, B. ProtGPT2 is a deep unsupervised language model for protein design. Nat. Commun. 13, 4348 (2022).\\n\\n20. Huang, B. et al. A backbone-centred energy function of neural networks for protein design. Nature 602, 523–528 (2022).\\n\\n21. Leinonen, R. et al. UniProt archive. Bioinformatics 20, 3236–3237 (2004).\\n\\n22. Bairoch, A. et al. The Universal Protein Resource (UniProt). Nucleic Acids Res. 33, D154–D159 (2005).\\n\\nNature Biotechnology | Volume 41 | August 2023 | 1099–1106\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\n23. Finn, R. D. et al. Pfam: the protein families database. Nucleic Acids Res. 42, D222–D230 (2014).\\n\\n24. Vaswani, A. et al. Attention is all you need. In 31st Conference on Neural Information Processing Systems (NIPS, 2017).\\n\\n25. Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT, 2019).\\n\\n26. Brown, T. B. et al. Language models are few-shot learners. In 34th Conference on Neural Information Processing Systems (NeurIPS, 2020).\\n\\n27. Zellers, R. et al. Defending against neural fake news. In 33rd Conference on Neural Information Processing Systems (NeurIPS, 2019).\\n\\n28. Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C. & Socher, R. CTRL: a conditional transformer language model for controllable generation. Preprint at arXiv https://doi.org/10.48550/ arXiv.1909.05858 (2019).\\n\\n29. AlQuraishi, M. The future of protein science will not be supervised. Some Thoughts on a Mysterious Universe https:// moalquraishi.wordpress.com/2019/04/01/the-future-of- protein-science-will-not-be-supervised/ (2019).\\n\\n30. Rives, A. et al. Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. Proc. Natl Acad. Sci. USA 118, e2016239118 (2021).\\n\\n31. Elnaggar, A. et al. ProtTrans: towards cracking the language of lifes code through self-supervised deep learning and high performance computing. IEEE Trans. Pattern Anal. Mach. Intell. 44, 7112–7127 (2021).\\n\\n32. Peters, M. E. et al. Deep contextualized word representations. In Proceedings of North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT, 2018).\\n\\n33. Howard, J. & Ruder, S. Universal language model fine-tuning for text classification. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL, 2018). 34. Radford, A., Narasimhan, K., Salimans, T. & Sutskever, I.\\n\\nImproving language understanding by generative pre-training. Preprint at https://s3-us-west-2.amazonaws.com/openai- assets/research-covers/language-unsupervised/language_ understanding_paper.pdf (2018).\\n\\n35. Biswas, S., Khimulya, G., Alley, E. C., Esvelt, K. M. & Church, G. M. Low-N protein engineering with data-efficient deep learning. Nat. Methods 18, 389–396 (2021).\\n\\n36. Pfaff, C. W. Constraints on language mixing: Intrasentential code-switching and borrowing in Spanish/English. Language 55, 291–318 (1979).\\n\\n37. Poplack, S. Sometimes I’ll start a sentence in Spanish Y TERMINO EN ESPAÑOL: toward a typology of code-switching. Linguistics 18, 581–618 (1980).\\n\\n38. Dathathri, S. et al. Plug and play language models: a simple approach to controlled text generation. In 8th International Conference on Learning Representations (ICLR, 2020). 39. Matthews, B. W. Comparison of the predicted and observed\\n\\nsecondary structure of T4 phage lysozyme. Biochim. Biophys. Acta 405, 442–451 (1975).\\n\\n40. Broendum, S. S., Buckle, A. M. & McGowan, S. Catalytic diversity and cell wall binding repeats in the phage-encoded endolysins. Mol. Microbiol. 110, 879–896 (2018).\\n\\n41. Love, M. J., Abeysekera, G. S., Muscroft-Taylor, A. C., Billington, C. & Dobson, R. C. J. On the catalytic mechanism of bacteriophage endolysins: opportunities for engineering. Biochim. Biophys. Acta. Proteins Proteom. 1868, 140302 (2020).\\n\\n1105\\n\\nArticle\\n\\n42. Martin, P. P. Potts Models And Related Problems In Statistical Mechanics (World Scientific, 1991).\\n\\n43. Thomas, J., Ramakrishnan, N. & Bailey-Kellogg, C. Graphical models of residue coupling in protein families. IEEE/ACM Trans. Comput. Biol. Bioinform. 5, 183–197 (2008).\\n\\n44. Weigt, M., White, R. A., Szurmant, H., Hoch, J. A. & Hwa, T. Identification of direct residue contacts in protein–protein interaction by message passing. Proc. Natl Acad. Sci. USA 106, 67–72 (2009).\\n\\n45. Balakrishnan, S., Kamisetty, H., Carbonell, J. G., Lee, S.-I. & Langmead, C. J. Learning generative models for protein fold families. Proteins 79, 1061–1078 (2011).\\n\\n46. Stein, R. R., Marks, D. S. & Sander, C. Inferring pairwise\\n\\ninteractions from biological data using maximum-entropy probability models. PLoS Comput. Biol. 11, e1004182 (2015). 47. Mirdita, M., Steinegger, M., Breitwieser, F., Söding, J. & Levy Karin, E. Fast and sensitive taxonomic assignment to metagenomic contigs. Binformatics 37, 3029–3031 (2021).\\n\\n48. Mooers, B. H. M., Tronrud, D. E. & Matthews, B. W. Evaluation at atomic resolution of the role of strain in destabilizing the temperature-sensitive T4 lysozyme mutant Arg 96 → His. Protein Sci. 18, 863–870 (2009).\\n\\n49. Baase, W. A., Liu, L., Tronrud, D. E. & Matthews, B. W. Lessons from\\n\\nthe lysozyme of phage T4. Protein Sci. 19, 631–641 (2010). 50. Kuroki, R., Weaver, L. H. & Matthews, B. W. A covalent enzyme–\\n\\nsubstrate intermediate with saccharide distortion in a mutant T4 lysozyme. Science 262, 2030–2033 (1993).\\n\\n51. Mchaourab, H. S., Oh, K. J., Fang, C. J. & Hubbell, W. L. Conformation of T4 lysozyme in solution. Hinge-bending motion and the substrate-induced conformational transition studied by site-directed spin labeling. Biochemistry 36, 307–316 (1997).\\n\\n52. Kim, J.-K. et al. BetaCavityWeb: a webserver for molecular voids and channels. Nucleic Acids Res. 43, W413–W418 (2015).\\n\\nNature Biotechnology | Volume 41 | August 2023 | 1099–1106\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\n53. Rost, B. Twilight zone of protein sequence alignments. Protein Eng. 12, 85–94 (1999).\\n\\n54. Pearson, W. R. An introduction to sequence similarity (‘homology’) searching. Curr. Protoc. Bioinforma. 3, 3.1 (2013). ChapterUnit. 55. Repecka, D. et al. Expanding functional protein sequence spaces using generative adversarial networks. Nat. Mach. Intell. 3, 324–333 (2021).\\n\\n56. Ruder, S., Peters, M. E., Swayamdipta, S. & Wolf, T. Transfer learning in natural language processing. In Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics (eds Jill Burstein, J., Doran, C. & Solorio T.) (Association for Computational Linguistics, 2019).\\n\\n57. Huh, M., Agrawal, P. & Efros, A. A. What makes ImageNet good for transfer learning? Preprint at arXiv https://doi.org/10.48550/ arXiv.1608.08614 (2016).\\n\\n58. LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436–444 (2015).\\n\\n59. Norn, C. et al. Protein sequence design by conformational landscape optimization. Proc. Natl Acad. Sci. USA 118, e2017228118 (2021).\\n\\n60. Anand, N. et al. Protein sequence design with a learned potential. Nat. Commun. 13, 746 (2022).\\n\\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\\n\\nSpringer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.\\n\\n© The Author(s), under exclusive licence to Springer Nature America, Inc. 2023\\n\\n1106\\n\\nArticle\\n\\nMethods Training data curation To train ProGen, we collected a universal protein sequence dataset con- taining 281 million non-redundant protein sequences (from >19,000 Pfam23 families) and associated metadata (as control tags) from Uni- Parc21, UniprotKB22, Pfam23 and NCBI taxonomic information61 (Fig. 1d and Supplementary Table 1). The amino acid vocabulary consisted of the standard 25 amino acids designations in IUPAC62. The control tags were divided into two categories: (1) keyword tags and (2) taxonomic tags. Following the definitions laid out in the UniprotKB controlled, hierarchical vocabulary of keywords (many of which are derived from Gene Ontology (GO) terms63), the control keyword tags included 1,100 terms ranging from cellular component, biological process, and molec- ular function terms. The taxonomic tags include 100,000 terms from the NCBI taxonomy across the eight standard taxonomic ranks. The aggregated dataset was split into a training set of size 280 million and two test sets, an out-of-distribution test set (OOD-test) of size 100,000 from 20 protein families and a randomly sampled in-domain test set (ID-test) of size 1 million, that were held out for training and used for evaluation. After model training on the training database, the model was further trained, that is fine tuned, to the following datasets for generation and classification tasks.\\n\\nFor fine tuning on lysozyme proteins, five protein families from the Pfam database were selected, phage lysozyme (PF00959), pesticin (PF16754), glucosaminidase (PF01832), glycoside hydrolase family 108 (PF05838) and transglycosylase (PF06737), yielding a total of 55,948 sequences. Proteins were provided to the model during fine tuning as unaligned protein sequences with one control tag prepended for the protein family designation. For fine tuning on CM proteins, a search with HHBlits and blastp was performed with residues 1–95 of EcCM (the CM domain of the E. coli CM-prephenate dehydratase, the P-protein) yielding 20,214 sequences. For fine tuning on MDH proteins, the l-lactate/MDH protein family from Interpro IPR001557 was selected with 17,094 sequences.\\n\\nConditional language modeling Let a = (a1, ..., ana) be a sequence of amino acids that specifies a protein of length na − 1 appended with an ‘end of sequence’ token. Let c = (c1, ..., cnc) be an associated set of descriptors such as protein family or source organism, that is, ‘control tags’, through which we would like to control generation of amino acid sequences. Let x = [c;a] be the sequence formed by prepending a control tag sequence to an amino acid sequence. The probability over such a combined sequence of length n = na + nc is then P(x). Language modeling decomposes the problem of generating x into a next-token prediction problem64, where a token can either be an amino acid or a control tag. We train a neural network with parameters θ to minimize the negative log-likelihood over a dataset D = {x1, … , x|D|}\\n\\nL (D) = − 1 |D| |D| ∑ k=1 1 nk nk ∑ i=1 log pθ (xk i |xk <i) (1)\\n\\nA new protein a of length ma with desired properties encoded by a control tag sequence c of length mc can then be generated by sequentially sampling its constituent tokens: pθ(a1| c), pθ(a2| a1, c),…,pθ(aj| a<j, c) (ref. 65). Generation continues until the model generates an ‘end of sequence’ token.\\n\\nWe use a transformer-based24 neural network architecture for constructing ProGen. The transformer learns long-range context within sequences using a series of stacked layers, each containing a self-attention mechanism (Fig. 1e). The self-attention mechanism in each layer infers pairwise interaction relationships between all posi- tions in its input sequence. Stacking multiple self-attention layers allows us to learn multiple-residue interactions66. The transformer-based approach has been shown to be related to coevolutionary methods\\n\\nNature Biotechnology\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\nfor sequence design such as MRFs67, Potts models68 and Hopfield net- works69. In contrast to transformer-based language models that encode amino acid sequences for discriminative protein prediction tasks30,70,71, ProGen is a decoder transformer tailored for autoregressive genera- tion: it generates a sequence in a left-to-right manner, token-by-token, where the next token is conditioned on all previously generated tokens. The transformer architecture of ProGen has 36 layers, and 8 self-attention heads per layer and a total of 1.2 billion trainable neu- ral network parameters. We trained ProGen to minimize the nega- tive log-likelihood defined in Eq. 1 using this dataset with a batch size of 2,048 for 1 million iterations. Training was performed across 256 Google Cloud TPU v3 cores for 2 weeks. Once trained, ProGen could be used to generate protein sequences from scratch by specifying a control tag (for example, protein family identifier from Pfam; Fig. 1c).\\n\\nProGen training For training, we included each sequence and its reverse. We prepended each sequence with a corresponding subset of control tags. For a given sequence, there can be multiple versions across databases, each with their own associated control tags. We randomly sampled which set of control tags to use, but biased sampling toward SwissProt tags as they are manually verified. Additionally, we always included a sample with the sequence alone without control tags so that ProGen could be used to complete proteins using sequence data alone. We truncated all sequences to a maximum length of 512. Sequences of length less than 512 were padded, and padded tokens were excluded from the cost func- tion used for training. The average token length of control tags during pretraining was eight. Our model was implemented in TensorFlow and trained with a global batch size of 2048 distributed across 256 cores of a Cloud TPU v3 Pod for a fixed number of 1 million iterations, with no specific stopping criterion. The perplexity on a held-out test set was monitored and did not exceed training set perplexity throughout model training. Training took approximately 2 weeks using Adagrad with linear warmup from 0 to 1 x 10−2 over the initial 40,000 steps with a linear decay for the remainder of training. The model was initialized with pretrained weights of CTRL28, which was trained on an English language corpus.\\n\\nLysozyme generation Fine tuning involves making limited, computationally inexpensive, gradient updates to the parameters of the trained model. We fine tuned ProGen to the 55,948-sequence fine tuning dataset using the conditional language modeling loss function introduced in Eq. 1, using a separate control tag for each of the five lysozyme families. The fine tuning dataset was clustered at 80% sequence identity and 10% of the clusters were held-out as a validation set for hyperparameter optimization and stop- ping criteria. The model was fit for 4 epochs using the Adam optimizer72 with a learning rate of 0.0001, batch size of 2, gradient norm clipping73 threshold of 0.25, and a dropout74 rate of 0.1. We then applied sampling using the final checkpoint of the fine-tuned model. We generated 1 mil- lion artificial sequences from the learned conditional probability dis- tribution pθ (ai|a<i, c) using each of the five lysozyme families as a control tag c, and applying top-p sampling75, which zeros out the probability of the tail of the distribution during sampling, and uses a hyperparameter p to determine what fraction of the original distribution to keep. Lower p values result in sequences with a higher likelihood under the model, but lower diversity. We generated a batch of 1 million synthetic sequences (Supplementary Fig. 3) using p values that varied in [0.25,0.50,0.75], and applied the sequence selection criteria in the next section to determine which sequences to synthesize.\\n\\nLysozyme sequence selection We selected sequences for synthesis by ranking them using the com- bination of an adversarial discriminator27,76 and generative model log-likelihood scoring77. First, we trained an adversarial discrimina- tor to distinguish between natural lysozymes and ProGen-generated\\n\\nArticle\\n\\nlysozymes. A higher discriminator score indicates a protein sequence that is ‘semantically’ and ‘grammatically’ closer to natural sequences, but not necessarily one of high sequence identity to natural proteins. To train the discriminator, we generated a batch of samples from fine-tuned ProGen (with nucleus sampling turned off, or p = 1) that was the same size and distribution of families as our dataset of natural lysozymes. The discriminator architecture was a fine-tuned TAPE-BERT71. For robust- ness, we trained three discriminators using different random seeds. We assigned each sequence a discriminator score as the geometric mean of the probability of the sample being a natural sequence as pre- dicted by the three discriminators. We also assigned each sequence a log-likelihood score as the average per-token log-likelihood for each sample computed using the fine-tuned ProGen model and conditioned on the control tag used to generate the sequence, given by\\n\\nScore (a) = 1 na na ∑ i=1 log pθ (ai|a<i, c) (2)\\n\\nA higher log-likelihood score indicates a sequence close to the probability distribution of sequences seen in training. Model log-likelihoods are directly correlated with perplexity as a language modeling evaluation metric. We selected artificial sequences using separate rankings based on the discriminator and log-likelihood scores. We separately ranked candidate sequences in maximum sequence identity ranges of 40–50%, 50–60%, 60–70%, 70–80% and 80–90%. For each range, we added the top discriminator-ranked sequences, skipping any sequences that were >80% identical to any previously selected sequence, for a total of 90 sequences. Ten more sequences were added on the basis of ranking by generative model log-likelihood scores in each range, again skipping any sequences with >80% identity to any previously selected sequence.\\n\\nEvaluating ProGen on other protein systems We also evaluated ProGen on generation of CM and MDH proteins. We separately fine tuned ProGen on datasets of CM and MDH proteins using the Adam optimizer, a learning rate of 1 x 10−4, a gradient norm clipping threshold of 0.25, and a dropout rate of 0.1. We also prepended the CM and MDH data with control tags that corresponded to CM and MDH families in original training of ProGen. After fine tuning, we generated a set of 64,000 sequences using top-p sampling (p = 0.75) from the CM and MDH fine-tuned models, respectively. We measured concordance of the log-likelihoods of our model with protein func- tion data on CM and MDH sequences, and compared with bmDCA7 and ProteinGAN55 baselines, respectively. We computed the AUC in receiver operating characteristic (ROC) curves for predicting binary function labels from model scores. We computed model scores for each sequence in both CM and MDH by using the per-token model log-likelihood in Eq. 2. We used model scores for bmDCA given by negative energy of each CM sequence provided by the authors of the study7. We also applied thresholding at 0.42 norm relative enrichment to obtain binary labels for CM function, which roughly corresponds to the cutoff point between two modes that exist in CM function data, to be used for ROC curves, following the original study7.\\n\\nSince model likelihoods for GANs are intractable, we used discrimi- nator scores corresponding to the probability at which the ProteinGAN discriminator predicted each sample was real as a ProteinGAN model score for each MDH sequence. The MDH functional labels are binary, so no thresholding was needed to compute AUCs. For an ablation study on ProGen, we also evaluate: i) a randomly initialized LM that has the same architecture as ProGen and is fine tuned to the same task-specific data as ProGen (CM or MDH), but is not pretrained on a larger dataset; and ii) ProGen without task-specific fine tuning, conditioning on control tags for CM or MDH from the original ProGen pretraining data. After measuring the AUC of each model for each dataset, we used bootstrap- ping to compute the statistical significance of the difference in AUC of\\n\\nNature Biotechnology\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\nfine-tuned ProGen versus the reference method (bmDCA and ProGen ablations for CM, ProteinGAN and ProGen ablations for MDH). At each bootstrapping iteration, we resampled a new dataset of fitness and model score pairs the same size as the original dataset by randomly selecting data points from the original dataset with replacement. For each sample dataset, we compute the difference in AUC score between fine-tuned ProGen and the reference method. We drew a total of 10,000 bootstrapping samples, and the P value is given by the percentage of the samples where the baseline achieves an AUC greater than or equal to fine-tuned ProGen, multiplied by two to give two-tailed.\\n\\nMaterials All reagents were purchased from Thermo Fisher Scientific unless oth- erwise noted. DNAs used for in vitro translation were purchased from Twist Bioscience and DNAs used for E. coli expression and purification were purchased from VectorBuilder.\\n\\nHigh-throughput cell-free expression of lysozymes Lysozymes were expressed using the Tierra Bioscience cell-free expres- sion platform. Cell-free extracts for protein expression were prepared according to the methods of Sun et al.78 with the following modifications: Terrific Broth was used in lieu of 2xYT, cells were lysed in a single pass by French press at 10, 000 p.s.i, dithiothreitol was omitted from wash buff- ers, and run-off and dialysis steps were removed to streamline extract processing. Expression reactions were composed of cell-free extract, an energy buffer and a linear DNA template containing a promoter sequence, the protein sequence of interest, the sequence of a strep purification tag and a terminator sequence; reactions were carried out at 29 °C for 6 hours. Expression reactions for screening optimal affinity purification tag terminus were performed in 10 µL volumes; selected reactions with good expression were then scaled to 200 µL. Lysozymes were purified from expression reactions by affinity chromatography with elution by enzymatic cleavage with 3 C protease leaving a small sequence scar.\\n\\nHigh-throughput screening of lysozyme activity Purified cell-free synthesized lysozymes were assayed with the EnzChek Lysozyme Assay Kit (Thermo Fisher Scientific). The assay was per- formed according to protocol with minimal modifications. HEWL standards and purified proteins in buffer (100 mM Tris pH 7.4, 150 mM NaCl, 2 mM TCEP, 20% glycerol) were brought to 50 µl with reaction buffer (100 mM sodium phosphate pH 7.5, 100 mM NaCl, 2 mM NaN3) in a 96-well plate. Fifty microliters of DQ lysozyme substrate, fluorescein conjugate (1 mg ml−1) was added to each well and fluorescence (excita- tion 485/20; emission 528/20) was collected every 5 min with a Synergy 2 multi-mode microplate reader (BioTek) for 6 h at 37 °C.\\n\\nFor each 96-well plate, three random wells were dedicated for HEWL controls and three wells were dedicated for a negative control of ubiquitin expressed and purified on the Tierra Biosciences cell-free expression platform. A purified protein was considered functional if it exhibited a higher fluorescence than one standard deviation above the maximum fluorescence value of all negative controls. The relative activity for each protein was calculated by the following equation:\\n\\nRelative activity = rprotein − rnegative rHEWL − rnegative × mHEWL mprotein (3)\\n\\nWhere r is the linear rate of fluorescence increase in the initial 20 min of the fluorogenic assay and m is the mass of protein as determined by Bradford assay concentration and measured volumes.\\n\\nE. coli expression of lysozyme variants We chose five generated lysozyme variants (L008, L013, L038, L056, L070) for expression in E. coli on the basis of strength of signal in the in vitro assay, expression level in the cell-free system and max ID to natural proteins. Generated lysozyme variants, were codon\\n\\nArticle\\n\\noptimized for E. coli (Integrated DNA Technologies) with an HRV3C protease site N-terminal of the open reading frame. DNA was syn- thesized and cloned in-frame with a 5′ His6-tag in a pET vector and transformed into BL21(DE3) (Vectorbuilder). One liter of Terrific Broth (Fisher) was prewarmed to 37 °C before being inoculated with 10 ml overnight starter culture. Cultures were grown to 0.6 < OD600 < 1.0 before temperature was dropped to 16 °C for expression. Cultures were induced with 0.5 mM isopropyl β-d-1-thiogalactopyranoside (source) and protein expression was allowed to continue overnight. For induced cultures of L056 and L070, turbidity was observed in the spent medium after cells were pelleted at 3,500 r.c.f. for 30 min at 4 °C. Spent medium also harbored lysozyme activity as ascertained through fluorescence increase over time of the fluorescein-labeled M. Lysodeikticus cell wall substrate (EnzChek kit; Thermo Fisher). Spent medium was saved for protein purification (outlined below) and cell pellet frozen and stored at −20 °C. Variant L008 did not express under multiple different conditions. L013 and L038 expressed highly to inclusion bodies.\\n\\nPurification of L056 and L070 from spent medium Medium was split into two 0.5 l pools each. The first pools were loaded onto a 5 ml HisTrap FF NiNTA column (GE) using a peristaltic pump at room temperature. Columns were washed with 200 ml 30 mM HEPES pH 7.6, 150 mM NaCl, 25 mM imidazole, 0.5 mM TCEP. Columns were eluted with 25 ml 30 mM HEPES pH 7.6, 150 mM NaCl, 250 mM imida- zole, 0.5 mM TCEP. Eluates were concentrated to 8–10 ml and dialyzed against 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP with HRV3C protease added overnight at 4 °C. Dialyzed protein was put through an ortho 5 ml HisTrap FF NiNTA column (GE) to remove HRV3C protease and uncleaved lysozyme. Though highly pure by SDS-PAGE analysis, protein was further purified by size-exclusion chromatography and loaded on an S75 10/300 gl column pre-equilibrated with 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP. Two peaks were resolved for each variant that harbored lysozyme activity against the fluorescein-labeled M. Lysodeikticus cell wall substrate (EnzChek kit; Thermo Fisher). Indi- vidual peaks were pooled and protein concentration determined either by Bradford assay (Biorad) or by SDS-PAGE using colloidal coomassie (Thermo Fisher) and HEWL in-gel standards.\\n\\nThe second spent medium pools were batch bound to 5 ml HisPur NiNTA resin (Thermo Fisher) at 4 °C for 1 h before protein-bound resin was pelleted through centrifugation at 3,000 r.c.f. for 5 min at 4 °C. Protein-bound resin was resuspended with 25 ml 30 mM HEPES pH 7.6, 150 mM NaCl, 25 mM imidazole, 0.5 mM TCEP and applied to a gravity flow column (BioRad) at room temperature. Columns were washed with 200 ml 30 mM HEPES pH 7.6, 150 mM NaCl, 25 mM imidazole, 0.5 mM TCEP. Columns were eluted with 25 ml 30 mM HEPES pH 7.6, 150 mM NaCl, 250 mM imidazole, 0.5 mM TCEP. Eluates were concentrated to 8–10 ml and dialyzed against 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP with HRV3C protease added overnight at 4 °C. Lysozyme was separated from HRV3C protease by size-exclusion chromatography on an S75 10/300 gl column pre-equilibrated with 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP. Two peaks were resolved for each variant that harbored lysozyme activity against the fluorescein-labeled M. Lysodeikticus cell wall substrate (EnzChek kit; Thermo Fisher) that cor- responded to peaks observed in the first pool purification. Individual peaks were pooled and protein concentration determined either by Bradford assay (Biorad) or by SDS-PAGE using colloidal coomassie (Thermo Fisher) and HEWL in-gel standards.\\n\\nMichaelis–Menten kinetics of lysozyme variants using fluorescein-labeled M. lysodeikticus cell wall Fluorescein-labeled M. Lysodeikticus cell wall substrate (EnzChek kit; Thermo Fisher) was reconstituted in 30 mM HEPES pH 7.6, 150 mM NaCl to 1 mg ml−1, aliquoted and stored at −20 °C until use. A serial two- fold dilution series of substrate was prepared in 30 mM HEPES pH 7.6,\\n\\nNature Biotechnology\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\n150 mM NaCl and treated as a 2× solution for enzymatic assays. Enzyme concentration was calculated either through Bradford assay (Bio-Rad) or by SDS-PAGE, in-gel using Novex or Abcam Colloidal Coomassie stain against a HEWL standard (Alfa Aesar). Enzymes were diluted to between 10 and 100 nM in 30 mM HEPES pH 7.6, 150 mM NaCl (HEWL) or 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP (L056 and L070) and these stocks treated as a 2× solution for enzymatic assays. Kinetic assays were performed in a Tecan Spark 10 M plate reader using monochrometers with a fixed 20 nm bandpass filter in a 384-well black-bottom plate (Corning) at 10 µl final volume. Reactions were initiated by pipetting 5 µl of substrate into appropriate wells followed immediately by 5 µl of enzyme, mixed by pipetting before starting data acquisition. The dead time from reaction initiation to acquisition of first read was measured to be 24 s. For reactions carried out above ambient temperature (25 °C), the plate was preincubated at temperature for at least 5 min before reaction initiation. Initial velocities were calculated through linearly fitting fluorescence intensity (a.u.) versus time for the first 2 min of each reaction. Finally, velocities were converted from a.u. to fluorescein liberated through application of a fluorescein (Sigma) standard curve (Supplementary Fig. 7) and normalized to enzyme concentration. Averaged data (n = 3 technical replicates) were non-linearly fit to the Michaelis–Menten model (Eq. 4) in IgorPro 7 to report kcat in units of fluorescein liberated enzyme−1 min−1 and KM in units of g l−1 (the average molecular weight of the fluorescein-labeled M. Lysodeikticus cell wall substrate was unknown and likely heterogeneous).\\n\\nvo = kcat ∗ [substrate] KM + [substrate] (4)\\n\\nFor low ID lysozyme A5, the above protocol was altered slightly to accommodate lower catalytic activity of these variants: reaction volumes were increased to 20 µl, the plate was covered with an opti- cally transparent seal (Microseal ‘B’ seal; BioRad) to mitigate sample evaporation, fluorescence reads were taken every 5 min for 16 h with 5 s of linear plate shaking before each measurement to minimize pho- tobleaching of substrate and ensure substrate maintained homo- geneous dispersion during longer reactions. The rate of substrate photobleaching was measured using a buffer-only control and used as a background rate subtraction for initial rate determination.\\n\\nLysozyme kcat/KM extrapolation from pseudo-first-order kinetic data For the higher molecular weight L056 and L070 species whose KM val- ues were beyond the concentration regime of the fluorescein-labeled M. Lysodeikticus cell wall substrate (EnzChek kit; Thermo Fisher), the ratio kcat/KM was measured through pseudo-first-order kinetics where when [Enyzme] » Substrate the Michaelis–Menten model simplifies to Eq. 5. Fluorescein-labeled M. Lysodeikticus cell wall substrate was diluted to 0.01 g l−1 and this stock was treated as 2× for kinetic assays. Kinetic assays were performed in a Tecan Spark 10M plate reader using monochrometers with a fixed 20-nm bandpass filter in a 384-well black-bottom plate (Corning) at 10 µl final volume. The dead time from reaction initiation to acquisition of first read was measured at 24 s and the 0 s fluorescence intensity was measured through dilution of substrate with buffer. Reactions were initiated by pipetting 5 µl 2× enzyme into 5 µl 2× substrate in a prewarmed 384-well black assay plate (Corning). Five technical replicates were performed across four enzyme concentrations. The resultant data were not described by a single exponential model but were described by a double exponen- tial model (Eq. 6), likely owing to the heterogeneity of the substrate, and all data were fit in IgorPro 7. The reciprocal of the weighted sum of each tau component was taken to estimate a single kobs value for subsequent analysis (Eq. 7). To estimate kcat/KM, kobs values were plot- ted against enzyme concentration where the slope of a linear fitting is equal to kcat/KM.\\n\\nArticle\\n\\nkobs = kcat KM × [Enzyme]\\n\\n(− x tau1 ) (− x tau2\\n\\ny = yo + Amplitude1 × e\\n\\n+ Amplitude2 × e\\n\\n)\\n\\nk−1 obs = tau1 × Amplitude1 Amplitude2 + tau2 × Amplitude2 Amplitude1\\n\\nFor lowID lysozyme variants the above protocol was altered slightly to accommodate lower catalytic activity of these variants: reaction volumes were increased to 20 µl where 2 µl 0.05 mg ml−1 (0.005 mg ml−1 final) of fluorescein-labeled M. lysodeikticus cell wall substrate was diluted with 18 µl lysozyme variant to initiate reactions, plate was covered with an optically transparent seal (Microseal ‘B’ seal; BioRad) to mitigate sample evaporation, fluorescence reads were taken every 5 min for 16 h with 5 s of linear plate shaking before each measure- ment to minimize photobleaching of substrate and ensure substrate maintained homogeneous dispersion during longer reactions. At least four enzyme concentrations were tested. Initial rates from these data (first 2 h of reaction) were also collected to determine enzyme relative activity according to Eq. 3 (Supplementary Fig. 10).\\n\\nCrystallization and structure determination of L056 Purified L056 was concentrated to 18.6 mg ml−1 in 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP. Crystals were identified from sitting drop vapor diffusion experiments set at 20 °C with a 1:1 ratio of 200 nl pro- tein and 200 nl well solution (0.1 M CHES 9.5 pH, 30 %w/v PEG 3000). Diffraction data were collected from a single crystal at Beamline 8.3.1. at the Advanced Light Source. Data were processed using XDS79 and a molecular replacement solution was identified using phaser80 with a trRosetta model of L056 as a search model. Significant translational non-crystallographic symmetry and differences with the search model resulted in maps that were initially hard to interpret. The initial model was improved using Refmac jelly body refinement81 using rebuilding using phenix.autobuild82 and the CCP4 buccaneer_pipeline83. The model was finalized and iteratively improved with multiple rounds of manual modification in Coot84 and refinement using phenix.refine85. The model is deposited as PDB accession 7RGR.\\n\\nLow max ID lysozyme sequence selection, expression and assay To evaluate whether ProGen can generate low max ID sequences, we generated an additional batch of sequences selected to have maximum sequence identities under 40% with respect to any natural protein. Since we could only test a limited number of proteins in vitro for this experiment, we modified our earlier generation procedure to bias the distribution of generations towards lysozyme families with higher measured functionality in previous experiments. We fine tuned an ensemble of four ProGen models only to lysozymes in PF00959 and PF05838 families. During generation, we used control tags for the two families, as well as control tags to indicate proteins with at least a 30% sequence similarity to L056 and L070, two proteins that we were able to successfully measure catalytic efficiency for in the previous batch. We then used a geometric ensemble of these four models to generate 1 million samples across these control tag settings with varying top-p values. We only kept generations with maximum sequence identities between 20–40%, and ranked these generations using discriminator scores using the same methodology as before, except with a larger 5B parameter discriminator that was pretrained as the T586 model, instead of TAPE-BERT. Our final batch included 12 sequences with the PF00959 control tag, 13 with the PF05838 control tag, 20 with the ‘L056 similar’ control tag, 20 with the ‘L070 similar’ control tag, 13 across control tags with under 30% maximum sequence identity and 20 sequences\\n\\nNature Biotechnology\\n\\n(5)\\n\\n(6)\\n\\n(7)\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\nfrom the 1 million generated for the original batch (with 10 at least 30% similar to L056 or L070, and 10 not similar), ranked by both the TAPE-BERT and T5 discriminators.\\n\\nHigh-throughput expression testing of low max ID lysozyme variants Variant sequences were appended with an N-terminal His6 and HRV3C tagged on their N-termini, codon optimized (VectorBuilder), cloned into a pET vector (VectorBuilder), transformed into BL21(DE3) and shipped from VectorBuilder as a glycerol stock in 96-well block. Vari- ants were inoculated into 1 ml ZYM-5052 autoinduction medium87 supplemented with 100 µg ml−1 carbenicillin in a 96-well deep block, covered with a gas-permeable seal and allowed to grow and expressed by shaking at 37 °C overnight (16 h). High-density expressed cultures were lysed by addition of detergent (Promega Fast Break Cell Lysis Reagent) supplemented with lysis buffer (30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP, cOmplete mini EDTA free protease inhibitor cock- tail (Roche), benzonase nuclease) with incubation under gentle shak- ing for at least 15 min at room temperature before whole expression SDS-PAGE gel samples were taken. Individual wells from 96-well block were transferred to microcentrifuge tubes, centrifuged at 21,000g for 5 min at room temperature, and the soluble fraction was transferred to a new 96-well block for soluble protein SDS-PAGE sample collection.\\n\\nExpression and purification of lowID lysozyme variants Variants A5, B6, C9, D4, D10 and E11 were chosen for follow up biochemi- cal characterization on the basis of their high expression and solubility (Supplementary Fig. 10). Variants were inoculated into 50–200 ml ZYM-5052 autoinduction medium87 supplemented with 100 µg ml−1 carbenicillin and allowed to grow and express constructs overnight (16 h) at 37 °C. High-density cell culture was pelleted by centrifugation at 4,000g for 20 min at 4 °C and resuspended to half the total culture volume in 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP, cOm- plete mini EDTA free protease inhibitor cocktail (Roche), benzonase nuclease. Resuspended cells were being lysed by addition of detergent (Promega Fast Break Cell Lysis Reagent) by rotating end-over-end at 4 °C for at least 15 min. Lysate was clarified by centrifugation at 4,000g for 20 min at 4 °C. Clarified lysate was batch bound to 0.5–1 ml dry volume of HisPur NiNTA resin (Thermo Fisher) for 45 min at 4 °C by rotating end-over-end. NiNTA bound variants were purified by either gravity or vacuum flow by washing resin with 75–125 ml 30 mM HEPES pH 7.6, 150 mM NaCl, 0.1 mM TCEP, 25 mM imidazole before eluting with 4 ml 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP, 250 mM imidazole. His6 tags were removed through addition of HRV3C protease and cleavage was allow to proceed either at room temperature for 2 h followed by buffer exchange using EconoPac 10 DG desalting columns (BioRad) equilibrated with 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP or dialyzed overnight at 4 °C against 30 mM HEPES pH 7.6, 150 mM NaCl, 0.5 mM TCEP. If total protein concentration was low, protein was concentrated in 3 kDa molecular weight cutoff Amico centrifugal filters. In-gel Coomassie quantification against HEWL standard curve was performed for all preparations and used for variant enzymology.\\n\\nStructure prediction methods To predict structure for the functional artificial sequences, we used Alpha- Fold214 in single-sequence mode (without multiple sequence alignment (MSA) information), with PDB templates, and 12 recycles. We performed structure prediction without an MSA as input so as to not heavily bias the structure prediction toward a known natural mode. The highest ranked predicted structure among five models was used. We attempted structure prediction without templates under varying settings (1–48 recycles) using three different implementations (AlphaFold2 run locally, ColabFold88 run on Google Colab and ColabFold run locally), however all predictions for our functional artificial sequences yielded unreliable results with predicted local distance difference test (pLDDT) scores below 60.\\n\\nArticle\\n\\nReporting summary Further information on research design is available in the Nature Port- folio Reporting Summary linked to this article.\\n\\nData availability All sequence databases used in this study are publicly available and include UniprotKB, UniParc, NCBI Taxonomy, Pfam, Uniref30, NCBI nr database and Interpro. Please refer to Supplementary Table 1 for more details. Sequences and activity data for natural and artificial lysozymes tested are in the Supplementary Material. Evaluation data for the CM experiments can be found in Russ et al.6. Evaluation data for the MDH experiments can be found in Repecka et al.52. The crystal structure datasets generated during the current study are available under PDB accession 7RGR. Source data are provided with this paper.\\n\\nCode availability Our code and checkpoints are publicly available on Zenodo and can be reproduced using the details provided in the Methods section on data preparation, model architecture and training protocol. Major components of our model architecture and training protocol can be reproduced using CTRL (https://github.com/salesforce/ctrl). The most updated and supported codebase can be found at https://github.com/ salesforce/progen.\\n\\nReferences 61. Federhen, S. The NCBI Taxonomy database. Nucleic Acids Res. 40,\\n\\nD136–D143 (2012).\\n\\n62. Pettit, L. D. The IUPAC stability constants database. Chem. Int. 28, 14–15 (2006).\\n\\n63. Ashburner, M. et al. Gene ontology: tool for the unification of biology. The Gene Ontology Consortium. Nat. Genet. 25, 25–29 (2000).\\n\\n64. Bengio, Y., Ducharme, R., Vincent, P. & Janvin, C. A neural probabilistic language model. J. Mach. Learn. Res. 3, 1137–1155 (2003).\\n\\n65. Madani, A. et al. ProGen: language modeling for protein generation. Preprint at arXiv https://doi.org/10.1101/2020. 03.07.982272 (2020).\\n\\n66. Vig, J. et al. BERTology meets biology: Interpreting attention in protein language models. In International Conference on Learning Representations (ICLR, 2020).\\n\\n67. Goyal, K., Dyer, C. & Berg-Kirkpatrick, T. Exposing the implicit energy networks behind masked language models via metropolis–hastings. In 10th International Conference on Learning Representations (ICLR, 2022).\\n\\n68. Bhattacharya, N. et al. Single layers of attention suffice to predict protein contacts. Preprint at bioRxiv https://doi. org/10.1101/2020.12.21.423882 (2020).\\n\\n69. Ramsauer, H. et al. Hopfield Networks is All You Need. Preprint at arXiv https://doi.org/10.48550/arXiv.2008.02217 (2020).\\n\\n70. Alley, E., Khimulya, G., Biswas, S., AlQuraishi, M. & Church, G. M. Unified rational protein engineering with sequence-based deep representation learning. Nat. Methods 16, 1315–1322 (2019).\\n\\n71. Rao, R. et al. Evaluating protein transfer learning with TAPE. Adv. Neural Inf. Process. Syst. 32, 9689–9701 (2019).\\n\\n72. Kingma, D. P. & Ba, J. Adam: a method for stochastic optimization. Preprint arXiv https://doi.org/10.48550/arXiv.1412.6980 (2014). 73. Pascanu, R., Mikolov, T. & Bengio, Y. On the difficulty of training\\n\\nrecurrent neural networks. In Proc. 30th International Conference on Machine Learning (eds. Dasgupta, S. & McAllester, D.) 1310– 1318 (PMLR, 2013).\\n\\n74. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. & Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overfitting. J. Mach. Learn. Res. 15, 1929–1958 (2014).\\n\\nNature Biotechnology\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\n75. Holtzman, A., Buys, J., Du, L., Forbes, M. & Choi, Y. The curious case of neural text degeneration. In 8th International Conference on Learning Representations (ICLR, 2020).\\n\\n76. Goodfellow, I. J. et al. Generative adversarial networks. In 28th Conference on Neural Information Processing Systems (NIPS, 2014).\\n\\n77. Koehn, P. Pharaoh: a beam search decoder for phrase-based statistical machine translation models. in Machine Translation: From Real Users to Research 115–124 (Springer, 2004).\\n\\n78. Sun, Z. Z. et al. Protocols for implementing an Escherichia coli based TX-TL cell-free expression system for synthetic biology. J. Vis. Exp. 16, e50762 (2013).\\n\\n79. Kabsch, W. XDS. Acta Crystallogr. D Biol. Crystallogr. 66, 125–132 (2010).\\n\\n80. McCoy, A. J. et al. Phaser crystallographic software. J. Appl. Crystallogr. 40, 658–674 (2007).\\n\\n81. Kovalevskiy, O., Nicholls, R. A., Long, F., Carlon, A. & Murshudov, G. N. Overview of refinement procedures within REFMAC5: utilizing data from different sources. Acta Crystallogr D Struct. Biol. 74, 215–227 (2018).\\n\\n82. Terwilliger, T. C. et al. Iterative model building, structure refinement and density modification with the PHENIX AutoBuild wizard. Acta Crystallogr. D Biol. Crystallogr. 64, 61–69 (2008).\\n\\n83. Hoh, S. W., Burnley, T. & Cowtan, K. Current approaches for\\n\\nautomated model building into cryo-EM maps using Buccaneer with CCP-EM. Acta Crystallogr D Struct. Biol. 76, 531–541 (2020). 84. Emsley, P., Lohkamp, B., Scott, W. G. & Cowtan, K. Features and development of Coot. Acta Crystallogr. D Biol. Crystallogr. 66, 486–501 (2010).\\n\\n85. Afonine, P. V. et al. Towards automated crystallographic structure refinement with phenix.refine. Acta Crystallogr. D Biol. Crystallogr. 68, 352–367 (2012).\\n\\n86. Raffel, C. et al. Exploring the limits of transfer learning with a unified text-to-text transformer. Preprint at arXiv https://doi. org/10.48550/arXiv.1910.10683 (2019).\\n\\n87. Studier, F. W. Protein production by auto-induction in high density shaking cultures. Protein Expr. Purif. 41, 207–234 (2005).\\n\\n88. Mirdita, M. et al. ColabFold: making protein folding accessible to all. Nat. Methods 19, 679–682 (2022).\\n\\nAcknowledgements We thank B. McCann, C. Gee, E. Procko, K. Trego, L. Varshney, N. Shirish Keskar and S. Savarese for their feedback at various stages of this project. We thank A. Cook, D. Lo and V. Nemali for operational support. Thanks also to the Salesforce Research Computing Infrastructure team and the Google Cloud TPU team for their help with computing resources, in addition to Twist Bioscience for DNA synthesis support. Beamline 8.3.1 at the Advanced Light Source is operated by the University of California Office of the President, Multicampus Research Programs and Initiatives grant MR-15-328599, the National Institutes of Health (R01 GM124149 and P30 GM124169), Plexxikon Inc. and the Integrated Diffraction Analysis Technologies program of the US Department of Energy Office of Biological and Environmental Research. The Advanced Light Source (Berkeley, CA) is a national user facility operated by Lawrence Berkeley National Laboratory on behalf of the US Department of Energy under contract number DE-AC02-05CH11231, Office of Basic Energy Sciences. Icons in one figure were created using BioRender (https://biorender.com). E.R.G. is supported by NIH F32-GM144982-01. J.S.F. was supported by NIH GM123159, NIH GM145238 and a Sanghvi-Agarwal Innovation Award.\\n\\nAuthor contributions A.M. conceived and designed the study in collaboration with S.S. A.M. and B.K. designed and performed machine learning modeling,\\n\\nArticle\\n\\ngeneration and scoring. B.P.M. performed the cell-free expression and activity assay and was supervised by Z.Z.S. E.R.G. performed the cell-based expression and kinetics assay and was supervised by J.S.F. J.M.H., J.L.O., J.S.F. performed the structure determination. A.M., S.S., B.K. and N.N. performed computational analysis, and were advised by C.X. R.S. provided advice on machine learning and computational methods. A.M., J.S.F. and N.N. wrote the manuscript with feedback and contributions from all authors, in particular from E.G. and B.K. N.N. supervised and managed the project.\\n\\nCompeting interests A.M. is a co-founder of Profluent Bio. All other authors declare no competing interests.\\n\\nNature Biotechnology\\n\\nhttps://doi.org/10.1038/s41587-022-01618-2\\n\\nAdditional information Supplementary information The online version contains supplementary material available at https://doi.org/10.1038/s41587-022-01618-2.\\n\\nCorrespondence and requests for materials should be addressed to Ali Madani or Nikhil Naik.\\n\\nPeer review information Nature Biotechnology thanks the anonymous reviewers for their contribution to the peer review of this work.\\n\\nReprints and permissions information is available at www.nature.com/reprints.\\n\\nnature portfolio\\n\\nCorresponding author(s):\\n\\nAli Madani, Nikhil Naik\\n\\nLast updated by author(s): Nov 9, 2022\\n\\nReporting Summary\\n\\nNature Portfolio wishes to improve the reproducibility of the work that we publish. This form provides structure for consistency and transparency in reporting. For further information on Nature Portfolio policies, see our Editorial Policies and the Editorial Policy Checklist.\\n\\nStatistics\\n\\nFor all statistical analyses, confirm that the following items are present in the figure legend, table legend, main text, or Methods section.\\n\\n| Confirmed\\n\\nThe exact sample size (n) for each experimental group/condition, given as a discrete number and unit of measurement\\n\\nA statement on whether measurements were taken from distinct samples or whether the same sample was measured repeatedly\\n\\nThe statistical test(s) used AND whether they are one- or two-sided\\n\\nOnly common tests should be described solely by name; describe more complex techniques in the Methods section.\\n\\nA description of all covariates tested\\n\\nA description of any assumptions or corrections, such as tests of normality and adjustment for multiple comparisons\\n\\nA full description of the statistical parameters including central tendency (e.g. means) or other basic estimates (e.g. regression coefficient) AND variation (e.g. standard deviation) or associated estimates of uncertainty (e.g. confidence intervals)\\n\\nFor hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted Give P values as exact values whenever suitable.\\n\\nFor Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings\\n\\nFor hierarchical and complex designs, identification of the appropriate level for tests and full reporting of outcomes\\n\\nEstimates of effect sizes (e.g. Cohen\\'s d, Pearson\\'s r), indicating how they were calculated\\n\\nOur web collection on statistics for biologists contains articles on many of the points above\\n\\nSoftware and code\\n\\nPolicy information about availability of computer code\\n\\nData collection | mmseqs2 was used for clustering and searching. pytorch 1.6 and tensorflow 1.14 was used to format data for model training. The progen code used in this study can be found at https://zenodo.org/record/7296780 and the newest version can be found in https://github.com/ salesforce/progen\\n\\nData analysis alphafold2 and trrosetta2 for predicting structures, pymol 2.4.0 was used for structure visualization and alignment, scikit-learn 0.24.1 and matplotlib 3.3.1 were used for figure creation, tools for structure determination were XDS79, phaser80, Refmac jelly body refinement81, phenix.autobuild82, CCP4 buccaneer_pipeline83, Coot84, phenix.refine8S\\n\\nFor manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published literature, software must be made available to editors and reviewers. We strongly encourage code deposition in a community repository (e.g. GitHub). See the Nature Portfolio guidelines for submitting code & software for further information\\n\\nz a Cc a\\n\\nxe} fe) = o =\\n\\nzB xe} fe) g\\n\\n5 vo}\\n\\n7 Cc 3 3 a <\\n\\nData\\n\\nPolicy information about availability of data\\n\\nAll manuscripts must include a data availability statement. This statement should provide the following information, where applicable:\\n\\n- Accession codes, unique identifiers, or web links for publicly available datasets\\n\\n- A description of any restrictions on data availability\\n\\n- For clinical datasets or third party data, please ensure that the statement adheres to our policy\\n\\nAll sequence databases used in this study are publicly available and include UniprotKB (https://www.uniprot.org/uniprot/), UniParc (https://www.uniprot.org/ uniparc/), NCBI Taxonomy (https://www.ncbi.nlm.nih.gov/taxonomy), Pfam (https://pfam.xfam.org/), Uniref30 (https://www.uniprot.org/uniref/), NCBI nr database (https://www.ncbi.nlm.nih.gov/refseq/about/nonredundantproteins/), and Interpro (https://www.ebi.ac.uk/interpro/). Sequences and activity data for natural and artificial lysozymes tested are in the Supplementary Material. Evaluation data for the chorismate mutase experiments can be found in Russ et al (https:// www.science.org/doi/10.1126/science.aba3304). Evaluation data for the malate dehydrogenase experiments can be found in Repecka et al (https:// www.nature.com/articles/s42256-021-00310-5). The crystal structure datasets generated during the current study are available in the Protein Data Bank repository, under accession 7RGR (https://www.rcsb.org/structure/7RGR).\\n\\nHuman research participants\\n\\nPolicy information about studies involving human research participants and Sex and Gender in Research.\\n\\nReporting on sex and gender\\n\\nex ( cultural both term: ed in\\n\\nPopulation characteristics\\n\\nhe human research participant g. age, genotypic Describe the rmation, filled out the behavioural & social sciences study\\n\\nRecruitment\\n\\ne how partici re recruited. Outline any potential self-selection bias or other biases that may be present and e are likely act results\\n\\nEthics oversight\\n\\nthat approved th\\n\\nNote that full information on the approval of the study protocol must also be provided in the manuscript.\\n\\nField-specific reporting\\n\\nPlease select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before making your selection.\\n\\nxX\\n\\nLife sciences Behavioural & social sciences Ecological, evolutionary & environmental sciences\\n\\nFor a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.odf\\n\\nLife sciences study design\\n\\nAll studies must disclose on these points even when the disclosure is negative\\n\\nSample size Sample sizes were not chosen based on a predetermined statistical method. It was chosen based on 96 well plates with 6 wells dedicated controls. Five samples were chosen for cell-based expression. Should be sufficient to support a claim that our method has the capability to engineer highly-active enzymes that are far in sequence space.\\n\\nData exclusions\\n\\nNo data was excluded.\\n\\nReplication All samples were replicated three times within a trial. Eight samples were replicated as an independent trial for high-throughput activity data by re-performing DNA synthesis, in vitro expression, and activity measurement. The samples characterized in cell-based assay were also present in the cell-free setting. All attempts at replication were successful.\\n\\nRandomization Natural samples were selected at random but was ensured to note have 80% sequence identity with any other natural sequence. Artificial sequences were selected in defined sequence identity bins and prioritized by generative model likelihood and adversarial discriminator scores. No two sequences across artificial sequences shared greater than 80% identity overlap.\\n\\nBlinding\\n\\nExperimentalists performing synthesis and characterization were blinded until completion of measurement.\\n\\nfor\\n\\nzl a Cc a\\n\\nme) fe) S =\\n\\na me) fe) S\\n\\n5 ©\\n\\nre c 3 3 2 <\\n\\nReporting for specific materials, systems and methods\\n\\nWe require information from authors about some types of materials, experimental systems and methods used in many studies. Here, indicate whether each material, system or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the appropriate section before selecting a response.\\n\\nMaterials & experimental systems Methods | Involved in the study | Involved in the study Antibodies ChIP-seq Eukaryotic cell lines Flow cytometry Palaeontology and archaeology MRI-based neuroimaging Animals and other organisms\\n\\nClinical data\\n\\nDual use research of concern\\n\\nz a Cc a\\n\\nxe} fe) = o =\\n\\nzB xe} fe) g\\n\\n5 vo}\\n\\n7 Cc 3 3 a <', metadata={'source': '/Users/lihongxuan/Downloads/s41587-022-01618-2.pdf'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results = extract_markdown(\"/Users/lihongxuan/Downloads/1801.07606.pdf\")\n",
    "\n",
    "extract_image_table(\"/Users/lihongxuan/Downloads/s41587-022-01618-2.pdf\", \"/Users/lihongxuan/Desktop/AIPI/Courses/AIPI540/AIPI-540-NLP/ZotoMind/interface/attachments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and Moura 2013; Shuman et al. 2013). However this model requires explicitly computing the Laplacian eigenvectors, which is impractical for real large graphs. A way to circumvent this problem is by approximating the spectral filter \\(g_{\\theta}\\) with Chebyshev polynomials up to \\(K^{th}\\) order [12]. In [11], In [11], Defferrard et al. applied this to build a \\(K\\)-localized ChebNet, where the convolution is defined as:\n",
      "\n",
      "\\[g_{\\theta}\\star\\mathbf{s}\\approx\\sum_{k=0}^{K}\\theta_{k}^{\\prime}T_{k}(L_{\\rm sym })\\mathbf{s}, \\tag{1}\\]\n",
      "\n",
      "where \\(\\mathbf{s}\\in R^{n}\\) is the signal on the graph, \\(g_{\\theta}\\) is the spectral filter, \\(\\star\\) denotes the convolution operator, \\(T_{k}\\) is the Chebyshev polynomials, and \\(\\theta^{\\prime}\\in R^{K}\\) is a vector of Chebyshev coefficients. By the approximation, the ChebNet is actually spectrum-free.\n",
      "\n",
      "In [11], Kipf and Welling simplified this model by limiting \\(K=1\\) and approximating the largest eigenvalue \\(\\lambda_{max}\\) of \\(L_{\\rm sym}\\) by 2. In this way, the convolution becomes\n",
      "\n",
      "\\[g_{\\theta}\\star\\mathbf{s}=\\theta\\left(I+D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}} \\right)\\mathbf{s}, \\tag{2}\\]\n",
      "\n",
      "where \\(\\theta\\) is the only Chebyshev coefficient left. They further applied a normalization trick to the convolution matrix:\n",
      "\n",
      "\\[I+D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}\\rightarrow\\tilde{D}^{-\\frac{1}{2}}\\tilde{ A}\\tilde{D}^{-\\frac{1}{2}}, \\tag{3}\\]\n",
      "\n",
      "where \\(\\tilde{A}=A+I\\) and \\(\\tilde{D}=\\sum_{j}\\tilde{A}_{ij}\\).\n",
      "\n",
      "Generalizing the above definition of convolution to a graph signal with \\(c\\) input channels, i.e., \\(X\\in R^{n\\times c}\\) (each vertex is associated with a \\(c\\)-dimensional feature vector), and using \\(f\\) spectral filters, the propagation rule of this simplified model is:\n",
      "\n",
      "\\[H^{(l+1)}=\\sigma\\left(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2} }H^{(l)}\\Theta^{(l)}\\right), \\tag{4}\\]\n",
      "\n",
      "where \\(H^{(l)}\\) is the matrix of activations in the \\(l\\)-th layer, and \\(H^{(0)}=X\\), \\(\\Theta^{(l)}\\in R^{c\\times f}\\) is the trainable weight matrix in layer \\(l\\), \\(\\sigma\\) is the activation function, e.g., \\(ReLU(\\cdot)=max(0,\\cdot)\\).\n",
      "\n",
      "This simplified model is called graph convolutional networks (GCNs), which is the focus of this paper.\n",
      "\n",
      "### Semi-Supervised Classification with GCNs\n",
      "\n",
      "In [11], the GCN model was applied for semi-supervised classification in a neat way. The model used is a two-layer GCN which applies a _softmax_ classifier on the output features:\n",
      "\n",
      "\\[Z=\\text{softmax}\\left(\\hat{A}\\ ReLU\\left(\\hat{A}X\\Theta^{(0)}\\right)\\Theta^{( 1)}\\right), \\tag{5}\\]\n",
      "\n",
      "where \\(\\hat{A}=\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}\\), \\(\\text{softmax}(x_{i})=\\frac{1}{2}exp(x_{i})\\) with \\(\\mathcal{Z}=\\sum_{i}exp(x_{i})\\). The loss function is defined as the cross-entropy error over all labeled examples:\n",
      "\n",
      "\\[\\mathcal{L}:=-\\sum_{i\\in\\mathcal{V}_{l}}\\sum_{f=1}^{F}Y_{if}\\ln Z_{if}, \\tag{6}\\]\n",
      "\n",
      "where \\(\\mathcal{V}_{l}\\) is the set of indices of labeled vertices and \\(F\\) is the dimension of the output features, which is equal to the number of classes. \\(Y\\in R^{|\\mathcal{V}_{l}|\\times F}\\) is a label indicator matrix. The weight parameters \\(\\Theta^{(0)}\\) and \\(\\Theta^{(1)}\\) can be trained via gradient descent.\n",
      "\n",
      "The GCN model naturally combines graph structures and vertex features in the convolution, where the features of unlabeled vertices are mixed with those of nearby labeled vertices, and propagated over the graph through multiple layers. It was reported in [11] that GCNs outperformed many state-of-the-art methods significantly on some benchmarks such as citation networks.\n",
      "\n",
      "## 3 Analysis\n",
      "\n",
      "Despite its promising performance, the mechanisms of the GCN model for semi-supervised learning have not been made clear. In this section, we take a closer look at the GCN model, analyze why it works, and point out its limitations.\n",
      "\n",
      "### Why GCNs Work\n",
      "\n",
      "To understand the reasons why GCNs work so well, we compare them with the simplest fully-connected networks (FCNs), where the layer-wise propagation rule is\n",
      "\n",
      "\\[H^{(l+1)}=\\sigma\\left(H^{(l)}\\Theta^{(l)}\\right). \\tag{7}\\]\n",
      "\n",
      "Clearly the only difference between a GCN and a FCN is the graph convolution matrix \\(\\hat{A}=\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}\\) (Eq. 5) applied on the left of the feature matrix \\(X\\). To see the impact of the graph convolution, we tested the performances of GCNs and FCNs for semi-supervised classification on the Cora citation network with 20 labels in each class. The results can be seen in Table 1. Surprisingly, even a one-layer GCN outperformed a one-layer FCN by a very large margin.\n",
      "\n",
      "**Laplacian Smoothing.** Let us first consider a one-layer GCN. It actually contains two steps. 1) Generating a new feature matrix \\(Y\\) from \\(X\\) by applying the graph convolution:\n",
      "\n",
      "\\[Y=\\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}X. \\tag{8}\\]\n",
      "\n",
      "2) Feeding the new feature matrix \\(Y\\) to a fully connected layer. Clearly the graph convolution is the key to the huge performance gain.\n",
      "\n",
      "Let us examine the graph convolution carefully. Suppose that we add a self-loop to each vertex in the graph, then the adjacency matrix of the new graph is \\(\\tilde{A}=A+I\\). The Laplacian smoothing [12] on each channel of the input features is defined as:\n",
      "\n",
      "\\[\\mathbf{\\hat{y}}_{i}=(1-\\gamma)\\mathbf{x}_{i}+\\gamma\\sum_{j}\\frac{\\tilde{a}_{ ij}}{d_{i}}\\mathbf{x}_{j}\\qquad(\\text{for}\\ \\ 1\\leq i\\leq n), \\tag{9}\\]\n",
      "\n",
      "\\begin{table}\n",
      "\\begin{tabular}{c c c c} One-layer & Two-layer & One-layer & Two-layer \\\\ FCN & FCN & GCN & GCN \\\\ \\hline\n",
      "0.530860 & 0.559260 & **0.707940** & **0.798361** \\\\ \\end{tabular}\n",
      "\\end{table}\n",
      "Table 1: GCNs vs. Fully-connected networks \n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
